{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:01.095170Z","iopub.status.busy":"2024-09-17T10:47:01.094805Z","iopub.status.idle":"2024-09-17T10:47:01.646146Z","shell.execute_reply":"2024-09-17T10:47:01.645213Z","shell.execute_reply.started":"2024-09-17T10:47:01.095123Z"},"trusted":true},"outputs":[],"source":["import os\n","from huggingface_hub import login\n","\n","login(token='')"]},{"cell_type":"markdown","metadata":{},"source":["Functions to format the queries properly for the endpoint."]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-17T10:47:01.648524Z","iopub.status.busy":"2024-09-17T10:47:01.647856Z","iopub.status.idle":"2024-09-17T10:47:01.655232Z","shell.execute_reply":"2024-09-17T10:47:01.654044Z","shell.execute_reply.started":"2024-09-17T10:47:01.648494Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def format_query(query):\n","    PREFIXES = \"\"\"PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n","PREFIX geof: <http://www.opengis.net/def/function/geosparql/>\n","PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n","PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n","PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n","PREFIX yago: <http://yago-knowledge.org/resource/>\n","PREFIX y2geor: <http://kr.di.uoa.gr/yago2geo/resource/>\n","PREFIX y2geoo: <http://kr.di.uoa.gr/yago2geo/ontology/>\n","PREFIX strdf: <http://strdf.di.uoa.gr/ontology#>\n","PREFIX uom: <http://www.opengis.net/def/uom/OGC/1.0/>\n","PREFIX owl: <http://www.w3.org/2002/07/owl#>\"\"\"\n","    \n","    query = PREFIXES + ' ' + query\n","    \n","    query = query.replace('strdf:within', 'geof:sfWithin')\n","    query = query.replace('strdf:contains', 'geof:sfContains')\n","    query = query.replace('strdf:overlaps', 'geof:sfOverlaps')\n","    query = query.replace('strdf:distance', 'geof:sfDistance')\n","    \n","    # Use regex to find and replace strdf:buffer patterns\n","    query = re.sub(r'strdf:buffer\\((\\?\\w+),\\s*\\d+,\\s*uom:\\w+\\)', r'\\1', query)\n","    \n","    return query"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:01.656665Z","iopub.status.busy":"2024-09-17T10:47:01.656366Z","iopub.status.idle":"2024-09-17T10:47:01.667780Z","shell.execute_reply":"2024-09-17T10:47:01.666827Z","shell.execute_reply.started":"2024-09-17T10:47:01.656641Z"},"trusted":true},"outputs":[],"source":["def gost_materialize_query(query: str):\n","    data = {\n","        \"query\": query\n","    }\n","\n","    headers = {\n","        'Content-Type': 'application/json'\n","    }\n","\n","    response = requests.post(\"\", headers=headers, data=json.dumps(data))\n","    \n","    if response.status_code == 200:\n","        return response.text\n","    else:\n","        print(\"Materialize failed:\", response.text)\n","        return (query)"]},{"cell_type":"markdown","metadata":{},"source":["Function that sends query to the endpoint and returns the result."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:01.669524Z","iopub.status.busy":"2024-09-17T10:47:01.669166Z","iopub.status.idle":"2024-09-17T10:47:02.091863Z","shell.execute_reply":"2024-09-17T10:47:02.090982Z","shell.execute_reply.started":"2024-09-17T10:47:01.669492Z"},"trusted":true},"outputs":[],"source":["import requests\n","import pandas as pd\n","from io import StringIO\n","\n","def graphdb_send_request(query, endpoint_url=\"\", accept_format='application/sparql-results+json'):\n","    \"\"\"\n","    Sends a SPARQL query to a GraphDB endpoint.\n","\n","    :param query: SPARQL query to be sent\n","    :param endpoint_url: URL of the GraphDB SPARQL endpoint\n","    :param accept_format: Desired response format (default is JSON)\n","    :return: Response from the endpoint\n","    \"\"\"\n","    # Format the query, this means add the correct prefixes and fix some endpoint issues with regex.\n","    query = format_query(query)\n","    original_query = query\n","    query = gost_materialize_query(query)\n","    \n","    headers = {\n","        'Accept': accept_format,\n","        'Content-Type': 'application/x-www-form-urlencoded'\n","    }\n","\n","    data = {\n","        'query': query\n","    }\n","    \n","    try:\n","        response = requests.post(endpoint_url, headers=headers, data=data, auth=requests.auth.HTTPBasicAuth('us', 'pas'))\n","\n","        if response.status_code == 200:\n","            if accept_format == 'application/sparql-results+json':\n","#                 print(response.json())\n","                json_response = response.json()\n","                return convert_json_to_csv(json_response)\n","            else:\n","#                 print(response.text)\n","                return response.text\n","        else:\n","            response.raise_for_status()\n","    except requests.exceptions.HTTPError as err:\n","        print(\"HTTP error (most likely invalid query)\")\n","        #print(query)\n","        #print(err)\n","    except Exception as err:\n","        print(err)\n","        print(\"Endpoint error ENDPOINT DOWN\")\n","        \n","def convert_json_to_csv(json_data):\n","    \"\"\"\n","    Converts JSON data to CSV format.\n","\n","    :param json_data: JSON data to be converted\n","    :return: CSV formatted data as a string\n","    \"\"\"\n","    if 'boolean' in json_data:\n","        # Handling boolean result\n","        headers = ['value']\n","        rows = [[json_data['boolean']]]\n","    else:\n","        # Extracting header and rows from JSON response\n","        headers = json_data['head']['vars']\n","        rows = [{var: result.get(var, {}).get('value', '') for var in headers} for result in json_data['results']['bindings']]\n","    \n","    # Creating DataFrame and converting to CSV\n","    df = pd.DataFrame(rows, columns=headers)\n","    csv_output = StringIO()\n","    df.to_csv(csv_output, index=False)\n","    \n","    return csv_output.getvalue()"]},{"cell_type":"markdown","metadata":{},"source":["Inference function."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:02.094881Z","iopub.status.busy":"2024-09-17T10:47:02.094473Z","iopub.status.idle":"2024-09-17T10:47:05.494744Z","shell.execute_reply":"2024-09-17T10:47:05.493756Z","shell.execute_reply.started":"2024-09-17T10:47:02.094854Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","def run_chat_inference(model, tokenizer, system_role, user_message):\n","    results = []\n","    \n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    \n","    messages = [\n","        {\"role\": \"system\", \"content\": system_role},\n","        {\"role\": \"user\", \"content\": user_message}\n","    ]\n","\n","    tokenizer.apply_chat_template(messages, tokenize=False)\n","\n","    model_inputs = tokenizer.apply_chat_template(messages, return_tensors = \"pt\").to(device)\n","    \n","    generated_ids = model.generate(\n","        model_inputs,\n","        max_new_tokens = 1000,\n","        do_sample = True,\n","    )\n","\n","    # Decode generated text\n","    generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    \n","    # Remove the system message\n","    if system_role in generated_text:\n","        generated_text = generated_text.split(system_role)[-1].strip()\n","\n","    # Remove the user message from the output to get only the assistant's response\n","    if user_message in generated_text:\n","        generated_text = generated_text.split(user_message)[-1].strip()\n","\n","    # Clear model from RAM\n","    del model\n","    torch.cuda.empty_cache()\n","    \n","    return generated_text"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:05.499217Z","iopub.status.busy":"2024-09-17T10:47:05.498554Z","iopub.status.idle":"2024-09-17T10:47:06.110336Z","shell.execute_reply":"2024-09-17T10:47:06.109565Z","shell.execute_reply.started":"2024-09-17T10:47:05.499179Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","\n","def run_chat_inference_llama(model, tokenizer, system_role, user_message):\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_role},\n","        {\"role\": \"user\", \"content\": user_message}\n","    ]\n","\n","    input_ids = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt=True,\n","        return_tensors=\"pt\"\n","    ).to(model.device)\n","\n","    terminators = [\n","        tokenizer.eos_token_id,\n","        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    outputs = model.generate(\n","        input_ids,\n","        max_new_tokens=128,\n","        eos_token_id=terminators,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_p=0.9,\n","    )\n","    response = outputs[0][input_ids.shape[-1]:]\n","    result = tokenizer.decode(response, skip_special_tokens=True)\n","\n","    return (result)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.112250Z","iopub.status.busy":"2024-09-17T10:47:06.111659Z","iopub.status.idle":"2024-09-17T10:47:06.131982Z","shell.execute_reply":"2024-09-17T10:47:06.131093Z","shell.execute_reply.started":"2024-09-17T10:47:06.112216Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","def run_inference(model, tokenizer, prompt):\n","    results = \"\"\n","    \n","    if tokenizer == None:\n","        # Generate output\n","        with torch.no_grad():\n","            outputs = model(prompt)\n","            \n","        # Decode and print output\n","        #print(\"Prompt:\", prompt)\n","        #print(\"Generated text:\" + outputs + \"\\n\")\n","        results = outputs\n","    else:\n","        # Move model to GPU\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        model.to(device)\n","        model.eval()  # Set model to evaluation mode\n","            \n","        # Tokenize prompt\n","        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","            \n","        # Generate output\n","        with torch.no_grad():\n","            outputs = model.generate(**inputs, \n","                            max_new_tokens=800,  # Set a maximum length for generated text\n","                            #do_sample=True,  # Enable sampling\n","                            #top_k=7,        # Top-k sampling\n","                            #top_p=0.1,      # Top-p sampling (nucleus sampling)\n","                            #num_return_sequences=1,\n","                            #repetition_penalty=1, # No penalty for instruction tuned models.\n","                            repetition_penalty=1.2, # Penalty on repeating tokens.\n","                            eos_token_id=tokenizer.eos_token_id,  # Specify EOS token ID\n","                            pad_token_id=tokenizer.pad_token_id  # Specify PAD token ID\n","                            )\n","        \n","        # Extract generated text\n","        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        # Remove the prompt text\n","        prompt_length = len(prompt)\n","        generated_text = generated_text[prompt_length:]\n","\n","        # Decode and print output\n","        #print(\"Prompt:\", prompt)\n","        #print(generated_text)\n","        results = generated_text\n","    \n","    # Clear model from RAM\n","    del model\n","    torch.cuda.empty_cache()\n","    \n","    return results\n","    \n","def compare_strings(str1, str2):\n","    # Split strings into words\n","    words1 = str1.split()\n","    words2 = str2.split()\n","    \n","    # Determine the length of the shorter list\n","    min_length = min(len(words1), len(words2))\n","    \n","    # Compare words from both lists\n","    for i in range(min_length):\n","        if words1[i] != words2[i]:\n","            print(f\"Difference found: '{words1[i]}' != '{words2[i]}'\")\n","    \n","    # Handle any extra words in the longer list\n","    if len(words1) > min_length:\n","        for i in range(min_length, len(words1)):\n","            print(f\"Extra word in first string: '{words1[i]}'\")\n","    \n","    if len(words2) > min_length:\n","        for i in range(min_length, len(words2)):\n","            print(f\"Extra word in second string: '{words2[i]}'\")\n","            \n","def find_prompt_end_position(generated_text, prompt):\n","    # Remove all spaces from the sentence and paragraph\n","    clean_paragraph = generated_text.replace(' ', '')\n","    clean_sentence = prompt.replace(' ', '')\n","    \n","    # Find the start position of the clean sentence in the clean paragraph\n","    start_position = clean_paragraph.find(clean_sentence)\n","    \n","    if start_position == -1:\n","        print(\"MAN\")\n","        return -1  # Sentence not found in the paragraph\n","    \n","    # Calculate the end position in the original paragraph\n","    sentence_length = len(clean_sentence)\n","    end_position_clean = start_position + sentence_length\n","    \n","    # Convert the end position to the original paragraph with spaces\n","    current_position = 0\n","    end_position_original = 0\n","    for char in generated_text:\n","        if char != ' ':\n","            current_position += 1\n","        end_position_original += 1\n","        if current_position == end_position_clean:\n","            break\n","    \n","    return end_position_original\n","\n","def Quantized_Inference(model, tokenizer, prompt):\n","    results = []\n","    \n","    # Move model to GPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.eval()  # Set model to evaluation mode\n","            \n","    # Tokenize prompt\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","            \n","    # Generate output\n","    with torch.no_grad():\n","        outputs = model.generate(**inputs, \n","                            max_new_tokens=250,  # Set a maximum length for generated text\n","                            #do_sample=True,  # Enable sampling\n","                            #top_k=7,        # Top-k sampling\n","                            #top_p=0.1,      # Top-p sampling (nucleus sampling)\n","                            #num_return_sequences=1,\n","                            repetition_penalty=1.2, # Penalty on repeating tokens.\n","                            eos_token_id=tokenizer.eos_token_id,  # Specify EOS token ID\n","                            pad_token_id=tokenizer.pad_token_id  # Specify PAD token ID\n","                            )\n","        \n","    # Extract generated text\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    \n","    # Remove the prompt text\n","    prompt_length = find_prompt_end_position(generated_text, prompt)\n","    generated_text = generated_text[prompt_length:]\n","    \n","    # Clear model from RAM\n","    del model\n","    torch.cuda.empty_cache()\n","    \n","    return generated_text"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.133762Z","iopub.status.busy":"2024-09-17T10:47:06.133279Z","iopub.status.idle":"2024-09-17T10:47:06.146995Z","shell.execute_reply":"2024-09-17T10:47:06.146208Z","shell.execute_reply.started":"2024-09-17T10:47:06.133730Z"},"trusted":true},"outputs":[],"source":["def insert_space_before_punctuation(query):\n","    # Function to replace punctuation outside of URIs\n","    def replace_punctuation(match):\n","        text = match.group(0)\n","        if text.startswith('<') and text.endswith('>'):\n","            # This is a URI, don't modify it\n","            return text\n","        else:\n","            # Add spaces before punctuation\n","            return text.replace('?', ' ?').replace('.', ' .')\n","\n","    # Regex pattern to match URIs and text between them\n","    pattern = r'(<[^>]+>|[^<>]+)'\n","\n","    # Apply the replacement function\n","    processed_query = re.sub(pattern, replace_punctuation, query)\n","\n","    return processed_query"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.148680Z","iopub.status.busy":"2024-09-17T10:47:06.148179Z","iopub.status.idle":"2024-09-17T10:47:06.158046Z","shell.execute_reply":"2024-09-17T10:47:06.157147Z","shell.execute_reply.started":"2024-09-17T10:47:06.148649Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def extract_uris(query):\n","    # Regular expression to match both fully expanded and prefixed URIs\n","    uri_pattern = r'<([^>]+)>|(\\b[a-zA-Z0-9_]+):([a-zA-Z0-9_]+)'\n","    \n","    uris = []\n","    matches = re.findall(uri_pattern, query)\n","    for match in matches:\n","        if match[0]:  # Fully expanded URI\n","            uris.append(match[0])\n","        else:  # Prefixed URI\n","            uris.append(f\"{match[1]}:{match[2]}\")\n","    return uris\n","\n","def expand_uris(query, prefix_dict):\n","    prefixed_pattern = r'(\\b[a-zA-Z0-9_]+):([a-zA-Z0-9_]+)'\n","    expanded_pattern = r'<([^>]+)>'\n","    \n","    expanded_uris = []\n","    \n","    # Find and expand prefixed URIs\n","    matches = re.findall(prefixed_pattern, query)\n","    for prefix, suffix in matches:\n","        if prefix in prefix_dict:\n","            expanded_uris.append(f\"{prefix_dict[prefix]}{suffix}\")\n","        else:\n","            expanded_uris.append(f\"{prefix}:{suffix}\")\n","    \n","    # Find and add already expanded URIs\n","    matches = re.findall(expanded_pattern, query)\n","    for uri in matches:\n","        expanded_uris.append(uri)\n","    \n","    return expanded_uris\n","\n","prefix_dict = {\n","    'geo': 'http://www.opengis.net/ont/geosparql#',\n","    'osm': 'http://www.openstreetmap.org/ontology#',\n","    'xsd': 'http://www.w3.org/2001/XMLSchema#',\n","    'geof': 'http://www.opengis.net/def/function/geosparql/',\n","    'uom': 'http://www.opengis.net/def/uom/OGC/1.0/'\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Function to generate queries with 6 example few shot learning and uri injection. (best experimental results)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.159762Z","iopub.status.busy":"2024-09-17T10:47:06.159470Z","iopub.status.idle":"2024-09-17T10:47:06.178088Z","shell.execute_reply":"2024-09-17T10:47:06.177322Z","shell.execute_reply.started":"2024-09-17T10:47:06.159738Z"},"trusted":true},"outputs":[],"source":["def get_plain_zero_shot_prompt(user_prompt):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the DBpedia knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","Human: {user_prompt}\n","Generator: ```\"\"\"\n","    return prompt\n","\n","def get_plain_three_shot_prompt(user_prompt):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the DBpedia knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","Human: In Breckland district, which forests are south of streams?\n","Generator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\n","Human: How many streams intersect with lakes?\n","Generator: ```SELECT (COUNT (DISTINCT ?p1) as ?streams) WHERE {{ ?p1 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?p1geo. ?p1geo geo:asWKT ?p1WKT. ?p2 rdf:type y2geoo:OSM_lake; geo:hasGeometry ?p2geo. ?p2geo geo:asWKT ?p2WKT. FILTER(geof:sfIntersects(?p1WKT, ?p2WKT)) }}```\n","Human: Which Municipalities are on Thessaly's border?\n","Generator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\n","Human: {user_prompt}\n","Generator: ```\"\"\"\n","    return prompt\n","\n","def get_zero_shot_uri_prompt(user_prompt, uris):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the Yago2Geo knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","Human: {user_prompt}\n","The generator must use these URIs to answer the question: {uris}\n","Generator: ```\"\"\"\n","    return prompt\n","\n","def get_zero_shot_uri_geos_prompt(user_prompt, uris):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the DBpedia knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","The resulting query may have to be in GeoSPARQL. The GeoSPARQL ontology is defined by:\n","URI: http://www.opengis.net/ont/geosparql\n","Classes: Feature, Feature Collection, Geometry, Geometry Collection, Spatial Object, Spatial Object Collection\n","Object Properties: default geometry, contains, covered by, covers, disjoint, equals, inside, meet, overlap, has area, has bounding box, has centroid, has default geometry, has geometry, has length, has perimeter length, has size, has spatial accuracy, has spatial resolution, has volume, disconnected, externally connected, equals, non-tangential proper part, non-tangential proper part inverse, partially overlapping, tangential proper part, tangential proper part inverse, contains, crosses, disjoint, equals, intersects, overlaps, touches, within\n","Datatype Properties: as DGGS, as GML, as GeoJSON, as KML, as WKT, coordinate dimension, dimension, has area in square meters, has length in meters, has perimeter length in meters, has metric size, has spatial accuracy in meters, has spatial resolution in meters, has volume in cubic meters, has serialization, is empty, is simple, spatial dimension\n","Human: {user_prompt}\n","The generator must use these URIs to answer the question: {uris}\n","Generator: ```\"\"\"\n","    return prompt\n","\n","def get_three_shot_uri_prompt(user_prompt, uris):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the DBpedia knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","Human: In Breckland district, which forests are south of streams?\n","The generator must use these URIs to answer the question: ['yago:Breckland_District', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_forest', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_stream', 'geo:hasGeometry', 'geo:asWKT', 'strdf:within', 'strdf:within', 'strdf:below']\n","Generator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\n","Human: How many streams intersect with lakes?\n","The generator must use these URIs to answer the question: ['rdf:type', 'y2geoo:OSM_stream', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_lake', 'geo:hasGeometry', 'geo:asWKT', 'geof:sfIntersects']\n","Generator: ```SELECT (COUNT (DISTINCT ?p1) as ?streams) WHERE {{ ?p1 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?p1geo. ?p1geo geo:asWKT ?p1WKT. ?p2 rdf:type y2geoo:OSM_lake; geo:hasGeometry ?p2geo. ?p2geo geo:asWKT ?p2WKT. FILTER(geof:sfIntersects(?p1WKT, ?p2WKT)) }}```\n","Human: Which Municipalities are on Thessaly's border?\n","The generator must use these URIs to answer the question: ['yago:Thessaly', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:GAG_Municipality', 'geo:hasGeometry', 'geo:asWKT', 'strdf:touches']\n","Generator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\n","Human: {user_prompt}\n","The generator must use these URIs to answer the question: {uris}\n","Generator: ```\"\"\"\n","    return prompt\n","\n","def get_six_shot_uri_prompt(user_prompt, uris):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the Yago2Geo knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","    Human: In Breckland district, which forests are south of streams?\n","The generator must use these URIs to answer the question: ['yago:Breckland_District', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_forest', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_stream', 'geo:hasGeometry', 'geo:asWKT', 'strdf:within', 'strdf:within', 'strdf:below']\n","Generator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\n","Human: How many streams intersect with lakes?\n","The generator must use these URIs to answer the question: ['rdf:type', 'y2geoo:OSM_stream', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_lake', 'geo:hasGeometry', 'geo:asWKT', 'geof:sfIntersects']\n","Generator: ```SELECT (COUNT (DISTINCT ?p1) as ?streams) WHERE {{ ?p1 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?p1geo. ?p1geo geo:asWKT ?p1WKT. ?p2 rdf:type y2geoo:OSM_lake; geo:hasGeometry ?p2geo. ?p2geo geo:asWKT ?p2WKT. FILTER(geof:sfIntersects(?p1WKT, ?p2WKT)) }}```\n","Human: Which Municipalities are on Thessaly's border?\n","The generator must use these URIs to answer the question: ['yago:Thessaly', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:GAG_Municipality', 'geo:hasGeometry', 'geo:asWKT', 'strdf:touches']\n","Generator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\n","Human: Which is the largest island in Ireland?\n","The generator must use these URIs to answer the question: ['strdf:area', 'yago:Republic_of_Ireland', 'geo:hasGeometry', 'geo:asWKT', 'y2geoo:OSM_island', 'geo:hasGeometry', 'geo:asWKT', 'geof:sfContains']\n","Generator: ```select distinct ?x (strdf:area(?lWKT) as ?area) where {{ yago:Republic_of_Ireland geo:hasGeometry ?geom . ?geom geo:asWKT ?mWKT . ?lake a y2geoo:OSM_island . ?lake geo:hasGeometry ?geol . ?geol geo:asWKT ?lWKT . FILTER (geof:sfContains(?mWKT, ?lWKT)) }} ORDER BY (?area) LIMIT 1```\n","Human: Is Crete south of Thessaly?\n","The generator must use these URIs to answer the question: ['http://yago-knowledge.org/resource/Crete', 'geo:hasGeometry', 'http://yago-knowledge.org/resource/Thessaly', 'geo:hasGeometry', 'geo:asWKT', 'geo:asWKT', 'strdf:below']\n","Generator: ```ASK {{ <http://yago-knowledge.org/resource/Crete> geo:hasGeometry ?geo1 . <http://yago-knowledge.org/resource/Thessaly> geo:hasGeometry ?geo2 . ?geo1 geo:asWKT ?geoWKT1 . ?geo2 geo:asWKT ?geoWKT2 . FILTER(strdf:below(?geoWKT1, ?geoWKT2)) }}```\n","Human: What is the population of Northern Ireland?\n","The generator must use these URIs to answer the question: ['xsd:integer', 'yago:Northern_Ireland', 'yago:hasPopulation']\n","Generator: ```SELECT (xsd:integer (?population) as ?pop) WHERE {{ yago:Northern_Ireland yago:hasPopulation ?population. }}\n","Human: {user_prompt}\n","The generator must use these URIs to answer the question: {uris}\n","Generator: ```\"\"\"\n","    \n","    return prompt\n","\n","def get_plain_three_shot_prompt(user_prompt):\n","    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the DBpedia knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n","Human: In Breckland district, which forests are south of streams?\n","Generator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\n","Human: Is Crete south of Thessaly?\n","Generator: ```ASK {{ <http://yago-knowledge.org/resource/Crete> geo:hasGeometry ?geo1 . <http://yago-knowledge.org/resource/Thessaly> geo:hasGeometry ?geo2 . ?geo1 geo:asWKT ?geoWKT1 . ?geo2 geo:asWKT ?geoWKT2 . FILTER(strdf:below(?geoWKT1, ?geoWKT2)) }}```\n","Human: Which Municipalities are on Thessaly's border?\n","Generator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\n","Human: {user_prompt}\n","Generator: ```\"\"\"\n","    return prompt"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.179594Z","iopub.status.busy":"2024-09-17T10:47:06.179332Z","iopub.status.idle":"2024-09-17T10:47:06.194919Z","shell.execute_reply":"2024-09-17T10:47:06.193992Z","shell.execute_reply.started":"2024-09-17T10:47:06.179571Z"},"trusted":true},"outputs":[],"source":["def get_six_shot_auri_prompt(user_prompt, uris):\n","    prompt = f\"\"\"Human: In Breckland district, which forests are south of streams?\n","The generator may use these URIs to answer the question: ['yago:Breckland_District', 'y2geoo:OS_DistrictWard', 'y2geoo:OSM_forest', 'y2geoo:OSM_stream']\n","Generator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\n","Human: How many streams intersect with lakes?\n","The generator may use these URIs to answer the question: ['y2geoo:OSM_lake']\n","Generator: ```SELECT (COUNT (DISTINCT ?p1) as ?streams) WHERE {{ ?p1 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?p1geo. ?p1geo geo:asWKT ?p1WKT. ?p2 rdf:type y2geoo:OSM_lake; geo:hasGeometry ?p2geo. ?p2geo geo:asWKT ?p2WKT. FILTER(geof:sfIntersects(?p1WKT, ?p2WKT)) }}```\n","Human: Which Municipalities are on Thessaly's border?\n","The generator may use these URIs to answer the question: []\n","Generator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\n","Human: Which is the largest island in Ireland?\n","The generator may use these URIs to answer the question: ['y2geoo:OSM_island', 'y2geoo:OSM_stream']\n","Generator: ```select distinct ?x (strdf:area(?lWKT) as ?area) where {{ yago:Republic_of_Ireland geo:hasGeometry ?geom . ?geom geo:asWKT ?mWKT . ?lake a y2geoo:OSM_island . ?lake geo:hasGeometry ?geol . ?geol geo:asWKT ?lWKT . FILTER (geof:sfContains(?mWKT, ?lWKT)) }} ORDER BY (?area) LIMIT 1```\n","Human: Is Crete south of Thessaly?\n","The generator may use these URIs to answer the question: []\n","Generator: ```ASK {{ yago:Crete geo:hasGeometry ?geo1 . yago:Thessaly geo:hasGeometry ?geo2 . ?geo1 geo:asWKT ?geoWKT1 . ?geo2 geo:asWKT ?geoWKT2 . FILTER(strdf:below(?geoWKT1, ?geoWKT2)) }}```\n","Human: What is the population of Northern Ireland?\n","The generator may use these URIs to answer the question: ['yago:Ireland']\n","Generator: ```SELECT (xsd:integer (?population) as ?pop) WHERE {{ yago:Northern_Ireland yago:'hasPopulation ?population. }}```\n","Human: {user_prompt}\n","The generator may use these URIs to answer the question: {uris}\n","Generator: ```\"\"\"\n","    \n","    return prompt\n","\n","def get_plain_six_shot_prompt(prompt):\n","    prompt = f\"\"\"Human: In Breckland district, which forests are south of streams?\n","Generator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\n","Human: How many streams intersect with lakes?\n","Generator: ```SELECT (COUNT (DISTINCT ?p1) as ?streams) WHERE {{ ?p1 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?p1geo. ?p1geo geo:asWKT ?p1WKT. ?p2 rdf:type y2geoo:OSM_lake; geo:hasGeometry ?p2geo. ?p2geo geo:asWKT ?p2WKT. FILTER(geof:sfIntersects(?p1WKT, ?p2WKT)) }}```\n","Human: Which Municipalities are on Thessaly's border?\n","Generator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\n","Human: Which is the largest island in Ireland?\n","Generator: ```select distinct ?x (strdf:area(?lWKT) as ?area) where {{ yago:Republic_of_Ireland geo:hasGeometry ?geom . ?geom geo:asWKT ?mWKT . ?lake a y2geoo:OSM_island . ?lake geo:hasGeometry ?geol . ?geol geo:asWKT ?lWKT . FILTER (geof:sfContains(?mWKT, ?lWKT)) }} ORDER BY (?area) LIMIT 1```\n","Human: Is Crete south of Thessaly?\n","Generator: ```ASK {{ <http://yago-knowledge.org/resource/Crete> geo:hasGeometry ?geo1 . <http://yago-knowledge.org/resource/Thessaly> geo:hasGeometry ?geo2 . ?geo1 geo:asWKT ?geoWKT1 . ?geo2 geo:asWKT ?geoWKT2 . FILTER(strdf:below(?geoWKT1, ?geoWKT2)) }}```\n","Human: What is the population of Northern Ireland?\n","Generator: ```SELECT (xsd:integer (?population) as ?pop) WHERE {{ yago:Northern_Ireland yago:'hasPopulation ?population. }}```\n","Human: {prompt}\n","Generator: ```\"\"\"\n","    \n","    return prompt    "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.196866Z","iopub.status.busy":"2024-09-17T10:47:06.196133Z","iopub.status.idle":"2024-09-17T10:47:06.209284Z","shell.execute_reply":"2024-09-17T10:47:06.208466Z","shell.execute_reply.started":"2024-09-17T10:47:06.196834Z"},"trusted":true},"outputs":[],"source":["# Run inference and cleanup.\n","def generate_URI_injected_query(model, tokenizer, user_prompt, gt_query, auris=None):\n","    # Direct extraction, NOTE: try expanded extraction.\n","#     uris = extract_uris(gt_query)\n","    \n","    prompt = get_six_shot_auri_prompt(user_prompt, auris)\n","    \n","#     results = run_chat_inference_llama(model, tokenizer, role, prompt)\n","    results = run_inference(model, tokenizer, prompt)\n","    query = results\n","#     start_index = results.find(\"```\")\n","    \n","#     # Extract the substring from the start of the string up to the first occurrence of ```\n","#     if start_index != -1:\n","#         query = query[start_index+3:]\n","#     else:\n","#         # If ``` is not found, keep the original string\n","#         query = query\n","\n","    end_index = query.find(\"```\")\n","    \n","    # Extract the substring from the start of the string up to the first occurrence of ```\n","    if end_index != -1:\n","        query = query[:end_index]\n","    else:\n","        # If ``` is not found, keep the original string\n","        query = query\n","        \n","    # Now remove the SPARQL prefix that the model adds.\n","    start_index = query.find(\"SPARQL\")\n","    if start_index == 0:\n","        # Remove the prefix and all characters leading up to it\n","        query = query[start_index + len(\"SPARQL\"):]\n","    \n","     # For llama 3 add spaces before the punctiations.\n","#     query = insert_space_before_punctuation(query)\n","    print(query)\n","    return query"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.210609Z","iopub.status.busy":"2024-09-17T10:47:06.210290Z","iopub.status.idle":"2024-09-17T10:47:06.220808Z","shell.execute_reply":"2024-09-17T10:47:06.220051Z","shell.execute_reply.started":"2024-09-17T10:47:06.210584Z"},"trusted":true},"outputs":[],"source":["# Run inference and cleanup.\n","def generate_query(model, tokenizer, user_prompt):\n","    # Direct extraction, NOTE: try expanded extraction.\n","    prompt = get_plain_six_shot_prompt(user_prompt)\n","    \n","#     results = run_chat_inference_llama(model, tokenizer, role, prompt)\n","    results = run_inference(model, tokenizer, prompt)\n","    query = results\n","#     start_index = results.find(\"```\")\n","    \n","#     # Extract the substring from the start of the string up to the first occurrence of ```\n","#     if start_index != -1:\n","#         query = query[start_index+3:]\n","#     else:\n","#         # If ``` is not found, keep the original string\n","#         query = query\n","\n","    end_index = query.find(\"```\")\n","    \n","    # Extract the substring from the start of the string up to the first occurrence of ```\n","    if end_index != -1:\n","        query = query[:end_index]\n","    else:\n","        # If ``` is not found, keep the original string\n","        query = query\n","        \n","    # Now remove the SPARQL prefix that the model adds.\n","    start_index = query.find(\"SPARQL\")\n","    if start_index == 0:\n","        # Remove the prefix and all characters leading up to it\n","        query = query[start_index + len(\"SPARQL\"):]\n","    \n","     # For llama 3 add spaces before the punctiations.\n","#     query = insert_space_before_punctuation(query)\n","    print(query)\n","    return query"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.224524Z","iopub.status.busy":"2024-09-17T10:47:06.224264Z","iopub.status.idle":"2024-09-17T10:47:06.233975Z","shell.execute_reply":"2024-09-17T10:47:06.233202Z","shell.execute_reply.started":"2024-09-17T10:47:06.224503Z"},"trusted":true},"outputs":[],"source":["# Llama 3 version\n","def generate_URI_injected_query_quantized(model, tokenizer, user_prompt, gt_query):\n","    # Direct extraction, NOTE: try expanded extraction.\n","    uris = extract_uris(gt_query)\n","    \n","    prompt = get_six_shot_uri_prompt(user_prompt, uris)\n","    \n","    #results = run_inference(model, tokenizer, prompt)\n","    results = Quantized_Inference(model, tokenizer, prompt)\n","    end_index = results.find(\"```\")\n","    query = results\n","    # Extract the substring from the start of the string up to the first occurrence of ```\n","    if end_index != -1:\n","        query = query[:end_index]\n","    else:\n","        # If ``` is not found, keep the original string\n","        query = query\n","    # Now remove the SPARQL prefix that the model adds.\n","    start_index = query.find(\"SPARQL\")\n","    if start_index == 0:\n","        # Remove the prefix and all characters leading up to it\n","        query = query[start_index + len(\"SPARQL\"):]\n","\n","    # For llama 3 add spaces before the punctiations.\n","    query = insert_space_before_punctuation(query)\n","    print(query)\n","    return query"]},{"cell_type":"markdown","metadata":{},"source":["Normalize queries before passing them to the endpoint to ensure uniformity across results."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.235250Z","iopub.status.busy":"2024-09-17T10:47:06.234962Z","iopub.status.idle":"2024-09-17T10:47:06.248474Z","shell.execute_reply":"2024-09-17T10:47:06.247625Z","shell.execute_reply.started":"2024-09-17T10:47:06.235217Z"},"trusted":true},"outputs":[],"source":["def normalize_variables(query):\n","    if query is None:\n","        return \"\"\n","    variable_pattern = re.compile(r\"\\?\\w+\")\n","    variables = variable_pattern.findall(query)\n","    normalized_query = query\n","    for i, var in enumerate(variables):\n","        normalized_query = normalized_query.replace(var, f\"?var{i}\")\n","    return normalized_query"]},{"cell_type":"markdown","metadata":{},"source":["To further ensure that correct results are not rejected, this custom comparisson function: "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.250411Z","iopub.status.busy":"2024-09-17T10:47:06.249550Z","iopub.status.idle":"2024-09-17T10:47:06.258193Z","shell.execute_reply":"2024-09-17T10:47:06.257310Z","shell.execute_reply.started":"2024-09-17T10:47:06.250386Z"},"trusted":true},"outputs":[],"source":["def csv_to_columns(csv_data):\n","    rows = csv_data.strip().split('\\n')\n","    data_rows = [row.split(',') for row in rows[1:]]  # Skip the header row\n","    columns = list(zip(*data_rows))  # Transpose rows to columns\n","    return columns\n","\n","def compare_csv_columns(csv1, csv2):\n","    columns1 = csv_to_columns(csv1)\n","    columns2 = csv_to_columns(csv2)\n","    \n","    set_columns1 = {tuple(col) for col in columns1}\n","    set_columns2 = {tuple(col) for col in columns2}\n","    \n","    #return not set_columns1.isdisjoint(set_columns2)\n","    \n","    common_columns = set_columns1.intersection(set_columns2)\n","    \n","    if common_columns:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"markdown","metadata":{},"source":["Load mistral."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:47:06.260120Z","iopub.status.busy":"2024-09-17T10:47:06.259320Z","iopub.status.idle":"2024-09-17T10:49:06.345833Z","shell.execute_reply":"2024-09-17T10:49:06.343003Z","shell.execute_reply.started":"2024-09-17T10:47:06.260094Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n","\n","model = AutoModelForCausalLM.from_pretrained(\"alpindale/Mistral-7B-v0.2-hf\", torch_dtype=torch.float16)\n","from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(\"alpindale/Mistral-7B-v0.2-hf\")"]},{"cell_type":"markdown","metadata":{},"source":["Mistral IT"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.349892Z","iopub.status.busy":"2024-09-17T10:49:06.349249Z","iopub.status.idle":"2024-09-17T10:49:06.358485Z","shell.execute_reply":"2024-09-17T10:49:06.357602Z","shell.execute_reply.started":"2024-09-17T10:49:06.349842Z"},"trusted":true},"outputs":[],"source":["# from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n","\n","# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", torch_dtype=torch.float16)\n","# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"]},{"cell_type":"markdown","metadata":{},"source":["Load 8 bit llama 3 8b instruct"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.360486Z","iopub.status.busy":"2024-09-17T10:49:06.360103Z","iopub.status.idle":"2024-09-17T10:49:06.377344Z","shell.execute_reply":"2024-09-17T10:49:06.376112Z","shell.execute_reply.started":"2024-09-17T10:49:06.360451Z"},"trusted":true},"outputs":[],"source":["# !pip install accelerate\n","# !pip install -i https://pypi.org/simple/ bitsandbytes"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.378809Z","iopub.status.busy":"2024-09-17T10:49:06.378457Z","iopub.status.idle":"2024-09-17T10:49:06.388646Z","shell.execute_reply":"2024-09-17T10:49:06.387408Z","shell.execute_reply.started":"2024-09-17T10:49:06.378774Z"},"trusted":true},"outputs":[],"source":["# # NOTE: If this crashes because accellerate or bits and bytes is not installed properly restart and clear shell outputs.\n","# # Load model directly\n","# from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n","# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", device_map=\"auto\", load_in_8bit=True)"]},{"cell_type":"markdown","metadata":{},"source":["8bit llama 3 8b"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.390487Z","iopub.status.busy":"2024-09-17T10:49:06.389955Z","iopub.status.idle":"2024-09-17T10:49:06.400005Z","shell.execute_reply":"2024-09-17T10:49:06.399074Z","shell.execute_reply.started":"2024-09-17T10:49:06.390454Z"},"trusted":true},"outputs":[],"source":["# !pip install accelerate\n","# !pip install -i https://pypi.org/simple/ bitsandbytes\n","    \n","# # Load model directly\n","# from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n","# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", device_map=\"auto\", load_in_8bit=True)"]},{"cell_type":"markdown","metadata":{},"source":["Load gemma 2b"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.401439Z","iopub.status.busy":"2024-09-17T10:49:06.401081Z","iopub.status.idle":"2024-09-17T10:49:06.411141Z","shell.execute_reply":"2024-09-17T10:49:06.409875Z","shell.execute_reply.started":"2024-09-17T10:49:06.401404Z"},"trusted":true},"outputs":[],"source":["# # Load model directly\n","# from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n","# model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\", device_map=\"auto\", torch_dtype=torch.float32)"]},{"cell_type":"markdown","metadata":{},"source":["Inference with GPT-4 Turbo."]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.412751Z","iopub.status.busy":"2024-09-17T10:49:06.412413Z","iopub.status.idle":"2024-09-17T10:49:06.422173Z","shell.execute_reply":"2024-09-17T10:49:06.421334Z","shell.execute_reply.started":"2024-09-17T10:49:06.412718Z"},"trusted":true},"outputs":[],"source":["# # Install the openai library if it's not already installed\n","# !pip install openai\n","\n","# import openai\n","\n","# def generate_response(prompt):\n","#     # Set your OpenAI API key here\n","    \n","#     response = openai.ChatCompletion.create(\n","#         model=\"gpt-4o-mini\",\n","#         messages=[\n","#             {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","#             {\"role\": \"user\", \"content\": prompt}\n","#         ],\n","#         max_tokens=150,\n","#         n=1,\n","#         stop=None,\n","#         temperature=0.7,\n","#     )\n","    \n","#     return response.choices[0].message['content']\n","\n","# # Example usage\n","# prompt = \"Generate a SPARQL query to retrieve the names and birthdates of authors who have written more than 3 books.\"\n","# result = generate_response(prompt)\n","# print(result)\n"]},{"cell_type":"markdown","metadata":{},"source":["concepts: 0.14"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-17T10:49:06.423500Z","iopub.status.busy":"2024-09-17T10:49:06.423233Z","iopub.status.idle":"2024-09-17T12:25:18.073178Z","shell.execute_reply":"2024-09-17T12:25:18.071992Z","shell.execute_reply.started":"2024-09-17T10:49:06.423478Z"},"trusted":true},"outputs":[],"source":["import json, requests\n","\n","with open('/kaggle/input/aurii-concepts-instances-dataset/concepts_instances_dataset.json', 'r') as file:\n","    original_dataset = json.load(file)\n","    \n","detailed_comp1 = 0\n","\n","detailed_comp2 = 0\n","\n","gt_results = []\n","gen_results = []\n","\n","i = 0\n","for key in original_dataset:\n","    print(i)\n","    i+=1\n","#     if i < 99:\n","#         continue\n","    query = original_dataset[key]['Query']\n","    # Normalize the query\n","#     query = normalize_variables(query)\n","    gt_result = graphdb_send_request(query)\n","    gt_results.append(gt_result)\n","    \n","    question = original_dataset[key]['Question']\n","    \n","    uris = original_dataset[key]['Gen_URI']\n","    gen_query1 = generate_URI_injected_query(model, tokenizer, question, None, uris)\n","#     gen_query2 = generate_query(model, tokenizer, question)\n","    # Normalize the query\n","    gen_result1 = graphdb_send_request(gen_query1)\n","#     gen_result2 = graphdb_send_request(gen_query2)\n","    gen_results.append(gen_result1)\n","    \n","    if gen_result1 and gt_result:\n","        comparisson = compare_csv_columns(gt_result, gen_result1)\n","        if comparisson == True:  \n","            detailed_comp1 += 1\n","        print(f\"URI: {detailed_comp1}\")\n","        \n","#     if gen_result2 and gt_result:\n","#         comparisson = compare_csv_columns(gt_result, gen_result2)\n","#         if comparisson == True:  \n","#             detailed_comp2 += 1\n","#         print(f\"PLAIN: {detailed_comp2}\")\n","        \n","print (detailed_comp/100)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-17T12:25:18.074010Z","iopub.status.idle":"2024-09-17T12:25:18.074339Z","shell.execute_reply":"2024-09-17T12:25:18.074196Z","shell.execute_reply.started":"2024-09-17T12:25:18.074182Z"},"trusted":true},"outputs":[],"source":["# def write_list_to_file(filename, data_list):\n","with open(filename, 'w') as file:\n","    for item in data_list:\n","        file.write(f\"{item}\\n\")\n","\n","# Write lists to files\n","write_list_to_file('gen.txt', gen_results)\n","write_list_to_file('gt.txt', gt_results)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5299649,"sourceId":8812575,"sourceType":"datasetVersion"},{"datasetId":5623080,"sourceId":9288757,"sourceType":"datasetVersion"},{"datasetId":5651610,"sourceId":9328230,"sourceType":"datasetVersion"},{"datasetId":5651612,"sourceId":9328232,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
