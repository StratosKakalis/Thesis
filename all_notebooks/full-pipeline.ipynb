{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8812575,"sourceType":"datasetVersion","datasetId":5299649},{"sourceId":9288757,"sourceType":"datasetVersion","datasetId":5623080},{"sourceId":9328230,"sourceType":"datasetVersion","datasetId":5651610},{"sourceId":9328232,"sourceType":"datasetVersion","datasetId":5651612}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load 100 question dataset.","metadata":{}},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\n#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\nlogin(token='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')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:21.462586Z","iopub.execute_input":"2024-09-22T13:36:21.462929Z","iopub.status.idle":"2024-09-22T13:36:22.160771Z","shell.execute_reply.started":"2024-09-22T13:36:21.462892Z","shell.execute_reply":"2024-09-22T13:36:22.159539Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/aurii-concepts-instances-dataset/concepts_instances_dataset.json', 'r') as file:\n    original_dataset = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:22.162512Z","iopub.execute_input":"2024-09-22T13:36:22.162834Z","iopub.status.idle":"2024-09-22T13:36:22.172812Z","shell.execute_reply.started":"2024-09-22T13:36:22.162800Z","shell.execute_reply":"2024-09-22T13:36:22.171836Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import json\n# import torch\n\n# with open('/kaggle/input/aurii-concepts-instances-dataset/concepts_instances_dataset.json', 'r') as file:\n#     original_dataset = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:22.174379Z","iopub.execute_input":"2024-09-22T13:36:22.175053Z","iopub.status.idle":"2024-09-22T13:36:22.184536Z","shell.execute_reply.started":"2024-09-22T13:36:22.175018Z","shell.execute_reply":"2024-09-22T13:36:22.183472Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline","metadata":{}},{"cell_type":"markdown","source":"## Model loading and inference.","metadata":{}},{"cell_type":"markdown","source":"* Load model","metadata":{}},{"cell_type":"code","source":"# import torch\n\n# from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n\n# model = AutoModelForCausalLM.from_pretrained(\"alpindale/Mistral-7B-v0.2-hf\", torch_dtype=torch.float16)\n# from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n# tokenizer = AutoTokenizer.from_pretrained(\"alpindale/Mistral-7B-v0.2-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:22.187140Z","iopub.execute_input":"2024-09-22T13:36:22.187994Z","iopub.status.idle":"2024-09-22T13:36:22.196747Z","shell.execute_reply.started":"2024-09-22T13:36:22.187961Z","shell.execute_reply":"2024-09-22T13:36:22.195633Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install -q accelerate bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:22.198161Z","iopub.execute_input":"2024-09-22T13:36:22.198509Z","iopub.status.idle":"2024-09-22T13:36:41.799839Z","shell.execute_reply.started":"2024-09-22T13:36:22.198470Z","shell.execute_reply":"2024-09-22T13:36:41.798634Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install -q peft","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:41.801385Z","iopub.execute_input":"2024-09-22T13:36:41.801710Z","iopub.status.idle":"2024-09-22T13:36:55.551291Z","shell.execute_reply.started":"2024-09-22T13:36:41.801674Z","shell.execute_reply":"2024-09-22T13:36:55.550103Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Stratos-Kakalis/norm_trunc_no_rdfs_8_epoch\", torch_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(\"alpindale/Mistral-7B-v0.2-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:36:55.552657Z","iopub.execute_input":"2024-09-22T13:36:55.552996Z","iopub.status.idle":"2024-09-22T13:47:41.721328Z","shell.execute_reply.started":"2024-09-22T13:36:55.552960Z","shell.execute_reply":"2024-09-22T13:47:41.720405Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad29d9ead4e4019be6411c577a62102"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee5e92ef9984ce3a6810f991191a78e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f32c79904e304ca8af6209a0d72bbc72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1f2ecec6f52418ba5dbbc52bc4db29c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b2dc98166124593b88519d46ebcc4ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79260365d5da4bee86f596bf5e68ce18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033609696969464abbf0219dbbf0d56c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eefb3737f7c14215b7c15a6f968517bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ab91f7bacb04c72955b109502317298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f52bc807aa1485b90e8f42cb7eb9c69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/960 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dbad9cd403d4f198d8d69ab9bd17a21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf610e6e0032442c9eed14e4bc8071dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb124355b8b4b4b9bc9a7feb2f87989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0943d9a61b4a93af7a131322c40be6"}},"metadata":{}}]},{"cell_type":"markdown","source":"* Inference function","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef run_chat_inference(model, tokenizer, system_role, user_message):    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    messages = [\n        {\"role\": \"system\", \"content\": system_role},\n        {\"role\": \"user\", \"content\": user_message}\n    ]\n\n    tokenizer.apply_chat_template(messages, tokenize=False)\n\n    model_inputs = tokenizer.apply_chat_template(messages, return_tensors = \"pt\").to(device)\n    \n    generated_ids = model.generate(\n        model_inputs,\n        max_new_tokens = 1000,\n        do_sample = True,\n    )\n\n    # Decode generated text\n    generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    \n    # Remove the system message\n    if system_role in generated_text:\n        generated_text = generated_text.split(system_role)[-1].strip()\n\n    # Remove the user message from the output to get only the assistant's response\n    if user_message in generated_text:\n        generated_text = generated_text.split(user_message)[-1].strip()\n\n    # Clear model from RAM\n    del model\n    torch.cuda.empty_cache()\n    \n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.722491Z","iopub.execute_input":"2024-09-22T13:47:41.722913Z","iopub.status.idle":"2024-09-22T13:47:41.731474Z","shell.execute_reply.started":"2024-09-22T13:47:41.722881Z","shell.execute_reply":"2024-09-22T13:47:41.730562Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def run_inference(model, tokenizer, prompt):\n    # Move model to GPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()  # Set model to evaluation mode\n            \n    # Tokenize prompt\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n            \n    # Generate output\n    with torch.no_grad():\n        outputs = model.generate(**inputs, \n                        max_new_tokens=800,  # Set a maximum length for generated text\n                        #do_sample=True,  # Enable sampling\n                        #top_k=7,        # Top-k sampling\n                        #top_p=0.1,      # Top-p sampling (nucleus sampling)\n                        #num_return_sequences=1,\n                        #repetition_penalty=1, # No penalty for instruction tuned models.\n                        repetition_penalty=1.2, # Penalty on repeating tokens.\n                        eos_token_id=tokenizer.eos_token_id,  # Specify EOS token ID\n                        pad_token_id=tokenizer.pad_token_id  # Specify PAD token ID\n                        )\n        \n    # Extract generated text\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n   \n    # Remove the prompt text\n    prompt_length = len(prompt)\n    generated_text = generated_text[prompt_length:]\n\n    # Decode and print output\n    #print(\"Prompt:\", prompt)\n    \n    # Clear model from RAM\n    del model\n    torch.cuda.empty_cache()\n    \n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.732915Z","iopub.execute_input":"2024-09-22T13:47:41.733506Z","iopub.status.idle":"2024-09-22T13:47:41.748185Z","shell.execute_reply.started":"2024-09-22T13:47:41.733455Z","shell.execute_reply":"2024-09-22T13:47:41.747384Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"* Quantized inference function for the quantized finetuned models.","metadata":{}},{"cell_type":"code","source":"def Quantized_Inference(model, tokenizer, prompt):\n    results = []\n    \n    # Move model to GPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)  # Ensure model is moved to the device\n    model.eval()  # Set model to evaluation mode\n            \n    # Tokenize prompt\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n            \n    # Generate output\n    with torch.no_grad():\n        outputs = model.generate(**inputs, \n                            max_new_tokens=400,  # Set a maximum length for generated text\n                            #do_sample=True,  # Enable sampling\n                            #top_k=7,        # Top-k sampling\n                            #top_p=0.1,      # Top-p sampling (nucleus sampling)\n                            #num_return_sequences=1,\n                            repetition_penalty=1.2, # Penalty on repeating tokens.\n                            eos_token_id=tokenizer.eos_token_id,  # Specify EOS token ID\n                            pad_token_id=tokenizer.pad_token_id  # Specify PAD token ID\n                            )\n        \n    # Extract generated text\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    # Remove the prompt text\n    prompt_length = len(prompt)\n    generated_text = generated_text[prompt_length:]\n    \n    # Clear model from RAM\n    del model\n    torch.cuda.empty_cache()\n    \n    return generated_text","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.751644Z","iopub.execute_input":"2024-09-22T13:47:41.751970Z","iopub.status.idle":"2024-09-22T13:47:41.768069Z","shell.execute_reply.started":"2024-09-22T13:47:41.751936Z","shell.execute_reply":"2024-09-22T13:47:41.767138Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"* Prompt creation function","metadata":{}},{"cell_type":"code","source":"# def create_prompt(question):\n#     prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the Yago2Geo knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n# Human: Where is Swansea located?\n# Generator: ```select ?geoWKT where {{ yago:Swansea geo:hasGeometry ?o.  ?o geo:asWKT ?geoWKT. }}```\n# Human: Which Greek regions have between 500000 and 1000000 inhabitants?\n# Generator: ```select ?region where {{ ?region a y2geoo:GAG_Region . ?region y2geoo:hasGAG_Population ?pop. filter(?pop < 1000000). filter(?pop > 500000). }}```\n# Human: Is Doolin to the south of Dublin?\n# Generator: ```ASK {{ <http://yago-knowledge.org/resource/Doolin> geo:hasGeometry ?o. ?o geo:asWKT ?geoWKT. <http://yago-knowledge.org/resource/Dublin> geo:hasGeometry ?o1. ?o1 geo:asWKT ?geoWKT1. FILTER(strdf:below(?geoWKT,?geoWKT1)) }}```\n# Human: {question}\n# Generator: ```\"\"\"\n#     return prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.769183Z","iopub.execute_input":"2024-09-22T13:47:41.769518Z","iopub.status.idle":"2024-09-22T13:47:41.785122Z","shell.execute_reply.started":"2024-09-22T13:47:41.769485Z","shell.execute_reply":"2024-09-22T13:47:41.784128Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# def create_prompt(question, uris):\n#     prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n# The generator is logical and creates each query by first explaining its thought process step-by-step.\n# Human: Where is Swansea located?\n# Generator: Let's think step by step. First, we want to find the location of Swansea, so we start with select ?geoWKT to specify that we need the geographic data.\n# Next, we need to identify how Swansea's location is stored in the knowledge graph. We use yago:Swansea geo:hasGeometry ?o. to find the geometric data related to Swansea.\n# Then, we need to extract the specific coordinates. We do this with ?o geo:asWKT ?geoWKT. to get the Well-Known Text (WKT) representation of Swansea's geometry.\n# Finally, we wrap these patterns in a where clause to structure our query properly. The final result: ```select ?geoWKT where {{ yago:Swansea geo:hasGeometry ?o.  ?o geo:asWKT ?geoWKT. }}```\n# Human: Which Greek regions have between 500000 and 1000000 inhabitants?\n# Generator: Let's think step by step. First, we want to find Greek regions with a population between 500,000 and 1,000,000, so we start with select ?region to specify that we need the region names.\n# Next, we need to identify which entities are Greek regions. We use ?region a y2geoo:GAG_Region to find entities classified as Greek regions.\n# Then, we need to get the population of these regions. We do this with ?region y2geoo:hasGAG_Population ?pop to find the population data associated with each region.\n# After that, we need to filter the results to only include regions with populations between 500,000 and 1,000,000. We use filter(?pop < 1000000) to exclude regions with more than 1,000,000 inhabitants and filter(?pop > 500000) to exclude regions with fewer than 500,000 inhabitants.\n# Finally, we wrap these patterns in a where clause to structure our query properly. The final result: ```select ?region where {{ ?region a y2geoo:GAG_Region . ?region y2geoo:hasGAG_Population ?pop. filter(?pop < 1000000). filter(?pop > 500000). }}```\n# Human: Is Doolin to the south of Dublin?\n# Generator: Let's think step by step. Question asks for yes/no answer: Use ASK query\n# Need to compare locations: Retrieve geometric data for both\n# geo:hasGeometry and geo:asWKT predicates for Doolin and Dublin\n# Check if one is south of the other: Use geospatial comparison function\n# FILTER with strdf:below function\n# Steps to build query:\n# a. Get Doolin's geometry: http://yago-knowledge.org/resource/Doolin\n# b. Get Dublin's geometry: http://yago-knowledge.org/resource/Dublin\n# c. Compare using FILTER and strdf:below Resulting query:\n# ```ASK {{ <http://yago-knowledge.org/resource/Doolin> geo:hasGeometry ?o. ?o geo:asWKT ?geoWKT. <http://yago-knowledge.org/resource/Dublin> geo:hasGeometry ?o1. ?o1 geo:asWKT ?geoWKT1. FILTER(strdf:below(?geoWKT,?geoWKT1)) }}```\n# Human: {question}\n# Generator: Let's think step by step.\"\"\"\n#     return prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.786800Z","iopub.execute_input":"2024-09-22T13:47:41.787202Z","iopub.status.idle":"2024-09-22T13:47:41.802672Z","shell.execute_reply.started":"2024-09-22T13:47:41.787155Z","shell.execute_reply":"2024-09-22T13:47:41.801533Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"* 6-shot prompt without CoT","metadata":{}},{"cell_type":"code","source":"def create_prompt(user_prompt, uris):\n    prompt = f\"\"\"You are an expert SPARQL query generator. For each question that the user supplies, you will convert it into a valid SPARQL query that can be used to answer the question. The query will be based on the Yago2Geo knowledge graph. The query should be enclosed by three backticks on new lines, denoting that it is a code block. You will not provide further details.\nHuman: In Breckland district, which forests are south of streams?\nThe generator must use these URIs to answer the question: ['yago:Breckland_District', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_forest', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_stream', 'geo:hasGeometry', 'geo:asWKT', 'strdf:within', 'strdf:within', 'strdf:below']\nGenerator: ```SELECT DISTINCT ?forest WHERE {{ yago:Breckland_District geo:hasGeometry ?o1 . ?o1 geo:asWKT ?geoWKT1 . ?forest rdf:type y2geoo:OSM_forest . ?forest geo:hasGeometry ?o2 . ?o2 geo:asWKT ?geoWKT2 . ?stream rdf:type y2geoo:OSM_stream . ?stream geo:hasGeometry ?o3 . ?o3 geo:asWKT ?geoWKT3 . FILTER (strdf:within(?geoWKT2, ?geoWKT1) && strdf:within(?geoWKT3, ?geoWKT1) && strdf:below(?geoWKT2, ?geoWKT3)) }}```\nHuman: How many streams intersect with lakes?\nThe generator must use these URIs to answer the question: ['rdf:type', 'y2geoo:OSM_stream', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:OSM_lake', 'geo:hasGeometry', 'geo:asWKT', 'geof:sfIntersects']\nGenerator: ```SELECT (COUNT (DISTINCT ?p1) as ?streams) WHERE {{ ?p1 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?p1geo. ?p1geo geo:asWKT ?p1WKT. ?p2 rdf:type y2geoo:OSM_lake; geo:hasGeometry ?p2geo. ?p2geo geo:asWKT ?p2WKT. FILTER(geof:sfIntersects(?p1WKT, ?p2WKT)) }}```\nHuman: Which Municipalities are on Thessaly's border?\nThe generator must use these URIs to answer the question: ['yago:Thessaly', 'geo:hasGeometry', 'geo:asWKT', 'rdf:type', 'y2geoo:GAG_Municipality', 'geo:hasGeometry', 'geo:asWKT', 'strdf:touches']\nGenerator: ```SELECT distinct ?rg where {{ yago:Thessaly geo:hasGeometry ?tgeo . ?tgeo geo:asWKT ?tgWKT . ?rg rdf:type y2geoo:GAG_Municipality . ?rg geo:hasGeometry ?rggeo . ?rggeo geo:asWKT ?rgWKT . FILTER (strdf:touches(?tgWKT,?rgWKT)) . }}```\nHuman: Which is the largest island in Ireland?\nThe generator must use these URIs to answer the question: ['strdf:area', 'yago:Republic_of_Ireland', 'geo:hasGeometry', 'geo:asWKT', 'y2geoo:OSM_island', 'geo:hasGeometry', 'geo:asWKT', 'geof:sfContains']\nGenerator: ```select distinct ?x (strdf:area(?lWKT) as ?area) where {{ yago:Republic_of_Ireland geo:hasGeometry ?geom . ?geom geo:asWKT ?mWKT . ?lake a y2geoo:OSM_island . ?lake geo:hasGeometry ?geol . ?geol geo:asWKT ?lWKT . FILTER (geof:sfContains(?mWKT, ?lWKT)) }} ORDER BY (?area) LIMIT 1```\nHuman: Is Crete south of Thessaly?\nThe generator must use these URIs to answer the question: ['http://yago-knowledge.org/resource/Crete', 'geo:hasGeometry', 'http://yago-knowledge.org/resource/Thessaly', 'geo:hasGeometry', 'geo:asWKT', 'geo:asWKT', 'strdf:below']\nGenerator: ```ASK {{ <http://yago-knowledge.org/resource/Crete> geo:hasGeometry ?geo1 . <http://yago-knowledge.org/resource/Thessaly> geo:hasGeometry ?geo2 . ?geo1 geo:asWKT ?geoWKT1 . ?geo2 geo:asWKT ?geoWKT2 . FILTER(strdf:below(?geoWKT1, ?geoWKT2)) }}```\nHuman: What is the population of Northern Ireland?\nThe generator must use these URIs to answer the question: ['xsd:integer', 'yago:Northern_Ireland', 'yago:hasPopulation']\nGenerator: ```SELECT (xsd:integer (?population) as ?pop) WHERE {{ yago:Northern_Ireland yago:'hasPopulation ?population. }}```\nHuman: {user_prompt}\nThe generator must use these URIs to answer the question: {uris}\nGenerator: ```\"\"\"\n    \n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.803882Z","iopub.execute_input":"2024-09-22T13:47:41.804240Z","iopub.status.idle":"2024-09-22T13:47:41.818843Z","shell.execute_reply.started":"2024-09-22T13:47:41.804195Z","shell.execute_reply":"2024-09-22T13:47:41.817807Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def create_prompt(question, uris):\n    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n\nHuman: {question}\nGenerator: ```\"\"\"\n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.820255Z","iopub.execute_input":"2024-09-22T13:47:41.820689Z","iopub.status.idle":"2024-09-22T13:47:41.832968Z","shell.execute_reply.started":"2024-09-22T13:47:41.820644Z","shell.execute_reply":"2024-09-22T13:47:41.832131Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def create_prompt(question, uris):\n    prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question. The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n\nHuman: {question}\nThe generator may use these URIs to answer the question: {uris}\nGenerator: ```\"\"\"\n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:58:04.403454Z","iopub.execute_input":"2024-09-22T14:58:04.404364Z","iopub.status.idle":"2024-09-22T14:58:04.409148Z","shell.execute_reply.started":"2024-09-22T14:58:04.404302Z","shell.execute_reply":"2024-09-22T14:58:04.408153Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"* Same CoT prompt but designed for automatic uri-injection. ","metadata":{}},{"cell_type":"code","source":"# def create_prompt(question, uris):\n#     prompt = f\"\"\"Generator is an expert SPARQL query generator. For each question that the user supplies, the generator will convert it into a valid SPARQL query that can be used to answer the question.\n# The generator may be provided with a list of URIs. Some of these URIs are relevant, while others are not. The generator must carefully identify and use only the correct URIs when they are provided. If the correct URIs are not available, the generator will rely on its understanding to construct the appropriate query.\n# The query should be enclosed by three backticks on new lines, denoting that it is a code block.\n# The generator is logical and creates each query by first explaining its thought process step-by-step.\n\n# Human: Where is Swansea located?\n# Provided URIs: yago:Swansea,y2geoo:OS_UnitaryAuthority\n# Generator: Let's think step by step. First, we want to find the location of Swansea, so we start with select ?geoWKT to specify that we need the geographic data.\n# Next, we need to identify how Swansea's location is stored in the knowledge graph. We use yago:Swansea geo:hasGeometry ?o. to find the geometric data related to Swansea.\n# Then, we need to extract the specific coordinates. We do this with ?o geo:asWKT ?geoWKT. to get the Well-Known Text (WKT) representation of Swansea's geometry.\n# Finally, we wrap these patterns in a where clause to structure our query properly. The final result: ```select ?geoWKT where {{ yago:Swansea geo:hasGeometry ?o.  ?o geo:asWKT ?geoWKT. }}```\n\n# Human: Which Greek regions have between 500000 and 1000000 inhabitants?\n# Provided URIs: yago:Greece\n# Generator: Let's think step by step. First, we want to find Greek regions with a population between 500,000 and 1,000,000, so we start with select ?region to specify that we need the region names.\n# Next, we need to identify which entities are Greek regions. We use ?region a y2geoo:GAG_Region to find entities classified as Greek regions. We do not need the provided URI of Greece.\n# Then, we need to get the population of these regions. We do this with ?region y2geoo:hasGAG_Population ?pop to find the population data associated with each region.\n# After that, we need to filter the results to only include regions with populations between 500,000 and 1,000,000. We use filter(?pop < 1000000) to exclude regions with more than 1,000,000 inhabitants and filter(?pop > 500000) to exclude regions with fewer than 500,000 inhabitants.\n# Finally, we wrap these patterns in a where clause to structure our query properly. The final result: ```select ?region where {{ ?region a y2geoo:GAG_Region . ?region y2geoo:hasGAG_Population ?pop. filter(?pop < 1000000). filter(?pop > 500000). }}```\n\n# Human: Is Doolin to the south of Dublin?\n# Provided URIs: yago:Doolin,yago:Dublin\n# Generator: Let's think step by step. Question asks for yes/no answer: Use ASK query\n# Need to compare locations: Retrieve geometric data for both\n# geo:hasGeometry and geo:asWKT predicates for Doolin and Dublin\n# Check if one is south of the other: Use geospatial comparison function\n# FILTER with strdf:below function\n# Steps to build query:\n# a. Get Doolin's and Dublin's geometry from the provided URIs: yago:Doolin and yago:Dublin\n# b. Compare using FILTER and strdf:below \n# The final result:\n# ```ASK {{ <http://yago-knowledge.org/resource/Doolin> geo:hasGeometry ?o. ?o geo:asWKT ?geoWKT. <http://yago-knowledge.org/resource/Dublin> geo:hasGeometry ?o1. ?o1 geo:asWKT ?geoWKT1. FILTER(strdf:below(?geoWKT,?geoWKT1)) }}```\n\n# Human: {question}\n# Provided URIs: {uris}\n# Generator: Let's think step by step.\"\"\"\n#     return prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.850861Z","iopub.execute_input":"2024-09-22T13:47:41.851190Z","iopub.status.idle":"2024-09-22T13:47:41.865380Z","shell.execute_reply.started":"2024-09-22T13:47:41.851157Z","shell.execute_reply":"2024-09-22T13:47:41.864322Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"* Query cleanup function","metadata":{}},{"cell_type":"code","source":"import re\n\ndef query_cleanup(results):\n    # Search for the pattern in the text\n#     match = re.search(r'```(.*?)```', results, re.DOTALL)\n    match = re.search(r'(.*?)```', results, re.DOTALL)\n    query = results\n    # If a match is found, return the matched text\n    if match:\n        query = match.group(1).strip()\n    \n    # Now remove the SPARQL prefix that the model adds.\n    start_index = query.find(\"SPARQL\")\n    if start_index == 0:\n        # Remove the prefix and all characters leading up to it\n        query = query[start_index + len(\"SPARQL\"):]\n\n    return query","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.866598Z","iopub.execute_input":"2024-09-22T13:47:41.866956Z","iopub.status.idle":"2024-09-22T13:47:41.882115Z","shell.execute_reply.started":"2024-09-22T13:47:41.866917Z","shell.execute_reply":"2024-09-22T13:47:41.881247Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Endpoint inference functions","metadata":{}},{"cell_type":"markdown","source":"* Gost materialization.","metadata":{}},{"cell_type":"code","source":"def gost_materialize_query(query: str):\n    data = {\n        \"query\": query\n    }\n\n    headers = {\n        'Content-Type': 'application/json'\n    }\n\n    response = requests.post(\"http://195.134.71.116:9090/materialize-api\", headers=headers, data=json.dumps(data))\n    \n    if response.status_code == 200:\n        return response.text\n    else:\n        print(\"Materialize failed:\", response.text)\n        return (query)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.883533Z","iopub.execute_input":"2024-09-22T13:47:41.884261Z","iopub.status.idle":"2024-09-22T13:47:41.897529Z","shell.execute_reply.started":"2024-09-22T13:47:41.884206Z","shell.execute_reply":"2024-09-22T13:47:41.896677Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"* Query fomatting function. This adds the correct prefixes and fixes some endpoint issues with regex.","metadata":{}},{"cell_type":"code","source":"def format_query(query):\n    PREFIXES = \"\"\"PREFIX geo: <http://www.opengis.net/ont/geosparql#>\nPREFIX geof: <http://www.opengis.net/def/function/geosparql/>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\nPREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\nPREFIX yago: <http://yago-knowledge.org/resource/>\nPREFIX y2geor: <http://kr.di.uoa.gr/yago2geo/resource/>\nPREFIX y2geoo: <http://kr.di.uoa.gr/yago2geo/ontology/>\nPREFIX strdf: <http://strdf.di.uoa.gr/ontology#>\nPREFIX uom: <http://www.opengis.net/def/uom/OGC/1.0/>\nPREFIX owl: <http://www.w3.org/2002/07/owl#>\"\"\"\n    \n    query = PREFIXES + ' ' + query\n    \n    query = query.replace('strdf:within', 'geof:sfWithin')\n    query = query.replace('strdf:contains', 'geof:sfContains')\n    query = query.replace('strdf:overlaps', 'geof:sfOverlaps')\n    query = query.replace('strdf:distance', 'geof:sfDistance')\n    \n    # Use regex to find and replace strdf:buffer patterns\n    query = re.sub(r'strdf:buffer\\((\\?\\w+),\\s*\\d+,\\s*uom:\\w+\\)', r'\\1', query)\n    \n    return query","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.898700Z","iopub.execute_input":"2024-09-22T13:47:41.899004Z","iopub.status.idle":"2024-09-22T13:47:41.909984Z","shell.execute_reply.started":"2024-09-22T13:47:41.898969Z","shell.execute_reply":"2024-09-22T13:47:41.909205Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"* Endpoint request function","metadata":{}},{"cell_type":"code","source":"import requests\nimport pandas as pd\nfrom io import StringIO\n\ndef graphdb_send_request(query, endpoint_url=\"http://88.197.53.158:7200/repositories/da4dte_final\", accept_format='application/sparql-results+json'):\n    \"\"\"\n    Sends a SPARQL query to a GraphDB endpoint.\n\n    :param query: SPARQL query to be sent\n    :param endpoint_url: URL of the GraphDB SPARQL endpoint\n    :param accept_format: Desired response format (default is JSON)\n    :return: Response from the endpoint\n    \"\"\"\n    # Format the query, this means add the correct prefixes and fix some endpoint issues with regex.\n    query = format_query(query)\n    original_query = query\n    query = gost_materialize_query(query)\n    \n    headers = {\n        'Accept': accept_format,\n        'Content-Type': 'application/x-www-form-urlencoded'\n    }\n\n    data = {\n        'query': query\n    }\n    \n    try:\n        response = requests.post(endpoint_url, headers=headers, data=data, auth=requests.auth.HTTPBasicAuth('admin', 'p@sx@'))\n\n        if response.status_code == 200:\n            if accept_format == 'application/sparql-results+json':\n#                 print(response.json())\n                json_response = response.json()\n                return convert_json_to_csv(json_response)\n            else:\n#                 print(response.text)\n                return response.text\n        else:\n            response.raise_for_status()\n    except requests.exceptions.HTTPError as err:\n        print(\"HTTP error (most likely invalid query)\")\n        #print(query)\n        #print(err)\n    except Exception as err:\n        print(err)\n        print(\"Endpoint error ENDPOINT DOWN\")\n        \ndef convert_json_to_csv(json_data):\n    \"\"\"\n    Converts JSON data to CSV format.\n\n    :param json_data: JSON data to be converted\n    :return: CSV formatted data as a string\n    \"\"\"\n    if 'boolean' in json_data:\n        # Handling boolean result\n        headers = ['value']\n        rows = [[json_data['boolean']]]\n    else:\n        # Extracting header and rows from JSON response\n        headers = json_data['head']['vars']\n        rows = [{var: result.get(var, {}).get('value', '') for var in headers} for result in json_data['results']['bindings']]\n    \n    # Creating DataFrame and converting to CSV\n    df = pd.DataFrame(rows, columns=headers)\n    csv_output = StringIO()\n    df.to_csv(csv_output, index=False)\n    \n    return csv_output.getvalue()","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:41.911549Z","iopub.execute_input":"2024-09-22T13:47:41.911954Z","iopub.status.idle":"2024-09-22T13:47:42.484144Z","shell.execute_reply.started":"2024-09-22T13:47:41.911904Z","shell.execute_reply":"2024-09-22T13:47:42.483375Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# # ------------------------\n# # ----- Quantization -----\n# # ------------------------\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True, \n#     bnb_4bit_use_double_quant=True, \n#     bnb_4bit_quant_type=\"nf4\", \n#     bnb_4bit_compute_dtype=torch.bfloat16\n# )\n \n# # -----------------\n# # ----- Model -----\n# # -----------------\n# model = AutoModelForCausalLM.from_pretrained(\n#     MODEL.model_id,\n#     device_map=\"auto\",\n#     torch_dtype=torch.bfloat16,\n#     quantization_config=bnb_config\n# )\n# for param in model.parameters():\n#     param.requires_grad = False\n#     if param.ndim ==1:\n#         param.data = param.data.to(torch.float32)\n    \n# model.gradient_checkpointing_enable()\n# model.enable_input_require_grads()\n\n# # compute_metrics(None, subset_test_dataset)\n# compute_metrics(None, dataset['test'])\n\n# # ----------------\n# # ----- LoRA -----\n# # ----------------\n# peft_config = LoraConfig(\n#     r=LORA_R,\n#     lora_alpha=LORA_ALPHA,\n#     lora_dropout=0.1,\n#     # target_modules = ['q_proj', 'k_proj', 'down_proj', 'v_proj', 'gate_proj', 'o_proj', 'up_proj'],\n#     bias = 'none',\n#     # modules_to_save = ['lm_head', 'embed_tokens'],\n#     task_type=\"CAUSAL_LM\"\n# )\n# model = get_peft_model(model, peft_config)\n \n# # --------------------\n# # ----- Training -----\n# # --------------------\n# args = TrainingArguments(\n#     output_dir=\"outputs\",                   # directory to save and repository id\n#     # Training length\n#     max_steps=MAX_STEPS,\n#     num_train_epochs=EPOCHS,\n#     # Important for VRAM\n#     per_device_train_batch_size=6,          # batch size per device during training\n#     gradient_accumulation_steps=2,          # number of steps before performing a backward/update pass\n#     # Other\n#     gradient_checkpointing=True,            # use gradient checkpointing to save memory\n#     optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n#     bf16=True,                              # use bfloat16 precision\n#     tf32=True,                              # use tf32 precision\n#     max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n#     warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n#     # lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n#     learning_rate=0.0002,\n#     # Logging\n#     logging_dir='logs',\n#     logging_steps=10,\n#     # Evaluation\n#     evaluation_strategy=\"steps\",            # evaluate every 'eval_steps'\n#     eval_steps=500,                         # evaluation step frequency\n#     save_steps=500,                         # save checkpoint every 'save_steps'\n#     load_best_model_at_end=True,            # load the best model at the end of training\n#     metric_for_best_model=\"correct\",        # metric to compare the best model\n#     greater_is_better=True\n# )\n\n# trainer = SFTTrainer(\n#     model=model,\n#     args=args,\n#     train_dataset=dataset['train'],\n#     eval_dataset=subset_test_dataset,\n#     dataset_text_field=\"input\",\n#     compute_metrics=compute_metrics,\n#     tokenizer=tokenizer,\n#     dataset_kwargs={\n#         \"add_special_tokens\": False,  # We template with special tokens\n#         \"append_concat_token\": False, # No need to add additional separator token\n#     }\n# )\n\n# # trainer.evaluate()\n\n# trainer.train(resume_from_checkpoint=True)\n\n# print(\"FULL EVALUATION\")\n# compute_metrics(None, dataset['test'])\n\n# # ---------------------------------\n# # ----- Upload to HuggingFace -----\n# # ---------------------------------\n# model.push_to_hub(\"SKefalidis/\" + MODEL.model_string + \"-\" + DATASET.dataset_string,\n#                   commit_message=str(MAX_STEPS) + \"-steps-\" + str(EPOCHS) + \"-epochs-4bit-r\" + str(LORA_R),\n#                   private=True)\n# tokenizer.push_to_hub(\"SKefalidis/\" + MODEL.model_string + \"-\" + DATASET.dataset_string,\n#                   commit_message=str(MAX_STEPS) + \"-steps-\" + str(EPOCHS) + \"-epochs-4bit-r\" + str(LORA_R),\n#                   private=True) ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:42.485535Z","iopub.execute_input":"2024-09-22T13:47:42.486400Z","iopub.status.idle":"2024-09-22T13:47:42.494206Z","shell.execute_reply.started":"2024-09-22T13:47:42.486335Z","shell.execute_reply":"2024-09-22T13:47:42.493361Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# model = PeftModel.from_pretrained(base_model, \"SKefalidis/Mistral-7B-v2-queries\") ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:42.495547Z","iopub.execute_input":"2024-09-22T13:47:42.495921Z","iopub.status.idle":"2024-09-22T13:47:42.509301Z","shell.execute_reply.started":"2024-09-22T13:47:42.495877Z","shell.execute_reply":"2024-09-22T13:47:42.508227Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# def __get_mistral_tokenizer() -> AutoTokenizer:\n#     tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n#     tokenizer.pad_token = tokenizer.unk_token#\"<PAD>\"\n#     tokenizer.padding_side = 'right'\n#     return tokenizer ","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:42.510504Z","iopub.execute_input":"2024-09-22T13:47:42.510846Z","iopub.status.idle":"2024-09-22T13:47:42.524305Z","shell.execute_reply.started":"2024-09-22T13:47:42.510798Z","shell.execute_reply":"2024-09-22T13:47:42.523472Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"* General pipeline handler.","metadata":{}},{"cell_type":"code","source":"# Handler, takes a question as input and returns the geometric data that answers it.\ndef ask_pipeline(question, uris=None):\n    # Generate appropriate prompt.\n    prompt = create_prompt(question, uris)\n    # Run inference on the LLM.\n#     generated_query = run_inference(model, tokenizer, prompt)\n    generated_query = Quantized_Inference(model, tokenizer, prompt)\n#     print(generated_query)\n#     generated_query = run_chat_inference(model, tokenizer, prompt, question)\n    # Extract the query alone from the results.\n    cleaned_query = query_cleanup(generated_query)\n    print(\"----\")\n    print(cleaned_query)\n    print(\"----\")\n    # Send the query to the endpoint.\n    results = graphdb_send_request(cleaned_query)\n    \n    # TO DO: visualize the results instead of just printing them.\n    #print (results)\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:42.525319Z","iopub.execute_input":"2024-09-22T13:47:42.525663Z","iopub.status.idle":"2024-09-22T13:47:42.535141Z","shell.execute_reply.started":"2024-09-22T13:47:42.525630Z","shell.execute_reply":"2024-09-22T13:47:42.534390Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy evaluation ","metadata":{}},{"cell_type":"markdown","source":"* Custom comparisson function","metadata":{}},{"cell_type":"code","source":"def csv_to_columns(csv_data):\n    rows = csv_data.strip().split('\\n')\n    data_rows = [row.split(',') for row in rows[1:]]  # Skip the header row\n    columns = list(zip(*data_rows))  # Transpose rows to columns\n    return columns\n\ndef compare_csv_columns(csv1, csv2):\n    columns1 = csv_to_columns(csv1)\n    columns2 = csv_to_columns(csv2)\n    \n    set_columns1 = {tuple(col) for col in columns1}\n    set_columns2 = {tuple(col) for col in columns2}\n    \n    #return not set_columns1.isdisjoint(set_columns2)\n    \n    common_columns = set_columns1.intersection(set_columns2)\n    \n    if common_columns:\n        return True\n    else:\n        return False","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:47:42.536359Z","iopub.execute_input":"2024-09-22T13:47:42.536737Z","iopub.status.idle":"2024-09-22T13:47:42.546555Z","shell.execute_reply.started":"2024-09-22T13:47:42.536695Z","shell.execute_reply":"2024-09-22T13:47:42.545720Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"* The evaluation on the 100 question dataset.","metadata":{}},{"cell_type":"code","source":"detailed_comp = 0\n\ngt_results = []\ngen_results = []\n\ni = 0\nfor key in original_dataset:\n    print(i)\n    i+=1\n    if i < 32:\n        continue\n#9 at 32\n    query = original_dataset[key]['Query']\n    \n    gt_result = graphdb_send_request(query)\n    gt_results.append(gt_result)\n    \n    question = original_dataset[key]['Question']\n    uris = original_dataset[key]['Gen_URI']\n    uris_string = ','.join(uris)\n#     uris_string = ''\n    \n    gen_result = ask_pipeline(question, uris_string)\n    gen_results.append(gen_result)\n    \n    if gen_result and gt_result:\n        comparisson = compare_csv_columns(gt_result, gen_result)\n        if comparisson == True:  \n            detailed_comp += 1\n        print(detailed_comp)\n        \nprint (detailed_comp/100)","metadata":{"execution":{"iopub.status.busy":"2024-09-22T15:46:00.516156Z","iopub.execute_input":"2024-09-22T15:46:00.517088Z","iopub.status.idle":"2024-09-22T16:12:45.224704Z","shell.execute_reply.started":"2024-09-22T15:46:00.517042Z","shell.execute_reply":"2024-09-22T16:12:45.223751Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  ?var0 rdf:type y2geoo:OSM_university . ?var0 geo:hasGeometry ?var2 . ?var2 geo:asWKT ?var4 .   <yago:geoentity_Athlone_3175986> geo:hasGeometry ?var5 . ?var5 geo:asWKT ?var7 .    FILTER(geof:sfWithin(?var4 , ?var7)) }\n----\n1\n32\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {   <yago:Norilsk> geo:hasGeometry ?var0 .  ?var0 geo:asWKT ?var2 .    <yago:Dublin> geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .     FILTER(strdf:above(?var2 , ?var5 )) }\n----\n1\n33\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (SUM(strdf:area(?var0)) as ?var1) WHERE {   yago:United_Kingdom geo:hasGeometry ?var2 .  ?var2 geo:asWKT ?var4 .    ?var5 rdf:type <y2geoo:OSM_forest> .     ?var5 geo:hasGeometry ?var7 .  ?var7 geo:asWKT ?var0 .      FILTER(geof:sfContains(?var4 , ?var0 )) }\n----\n1\n34\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSM_bridge .   ?var1 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    <yago:Republic_of_Ireland> geo:hasGeometry ?var6 .   ?var6 geo:asWKT ?var8 .     FILTER(strdf:intersects(?var5, ?var8))      BIND (strdf:difference(?var5, ?var8) as ?var10)     FILTER(strdf:areEqual(xsd:integer(\"0\"), strdf:yearsBetween(strdf:now(), ?var10 )) ) } ORDER BY DESC(strdf:yearsBetween(strdf:now(), ?var10 )) LIMIT 2\n----\n1\n35\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE { yago:County_Kilkenny geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n1\n36\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:Greece> geo:hasGeometry ?var0 .  ?var0 geo:asWKT ?var2 .   <yago:England> geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    FILTER(strdf:left(?var5 , ?var2 )) }\n----\n1\n37\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   y2geoo:OS_County geo:hasGeometry ?var2 .   ?var2 geo:asWKT ?var4 .     <yago:Texas>  geo:hasGeometry ?var5 .    ?var5 geo:asWKT ?var7 .      FILTER(strdf:within(?var4 , ?var7)) }\n----\n1\n38\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:Lake_Kerkini> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n1\n39\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_village .  ?var0 geo:hasGeometry ?var4.  ?var4 geo:asWKT ?var6.    FILTER(strdf:touches(?var7, ?var6))     ?var7 rdf:type y2geoo:OSM_village .  ?var7 geo:hasGeometry ?var9.  ?var9 geo:asWKT ?var11.      FILTER(geof:sfTouches(?var6, ?var11)) }\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T15:50:07.812+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n40\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_park;   geo:hasGeometry ?var3.   ?var3 geo:asWKT ?var5.    <y2geoo:OS_County_Eastleigh>  geo:hasGeometry ?var6.     ?var6 geo:asWKT ?var8.      FILTER(strdf:intersects(?var5, ?var8)) }\n----\n1\n41\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_city; geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_bay; geo:hasGeometry ?var7 .  ?var7 geo:asWKT ?var9 .     FILTER(geof:sfWithin(?var9 , ?var5 )) }\n----\n2\n42\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var0 rdf:type y2geoo:OSI_AdministrativeUnit .  ?var0 geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_lake .  ?var6 geo:hasGeometry ?var8 .  ?var8 geo:asWKT ?var10 .     FILTER(strdf:intersects(?var5 , ?var10 )) }\n----\n2\n43\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_stream; geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_island; geo:hasGeometry ?var7 .  ?var7 geo:asWKT ?var9 .     FILTER(strdf:intersects(?var5 , ?var9 ))      FILTER(xsd:greekLike(?var10)) }\n----\nHTTP error (most likely invalid query)\n44\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:geoentity_Chania_8133742> geo:hasGeometry ?var0 . ?var0 geo:asWKT ?var2 . <yago:geoentity_Athens_8100659> geo:hasGeometry ?var3 . ?var3 geo:asWKT ?var5 . FILTER(strdf:right(?var5,?var2)) }\n----\n2\n45\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (strdf:area(?var0) AS ?var1) WHERE {   <yago:West_Sussex> geo:hasGeometry ?var2 .  ?var2 geo:asWKT ?var0 }\n----\n2\n46\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   <yago:Plymouth> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    ?var0 rdf:type y2geoo:OS_DistrictWard;         geo:hasGeometry ?var5 .  ?var5 geo:asWKT ?var7 .     FILTER(strdf:intersects(?var3 , strdf:buffer(?var7 , 0, uom:metre))) ORDER BY DESC (strdf:area(?var7)) LIMIT 3 }\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T15:52:42.832+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n47\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {   <y2geoo:osm_area_USA> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .  ?var0 rdf:type y2geoo:GADM_2ndOrder_Area;   <geo:hasGeometry> ?var5 .  ?var5 geo:asWKT ?var7 .  FILTER(strdf:crosses(?var3 , ?var7 )) } ORDER BY DESC (strdf:area(?var7)) LIMIT 1\n----\n2\n48\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_town;   geo:hasGeometry ?var3.   ?var3 geo:asWKT ?var5.    <yago:geoentity_Norfolk_7968484> geo:hasGeometry ?var6.     ?var6 geo:asWKT ?var8.      FILTER(strdf:within(?var5, ?var8))   ?var0 <POPULATION> ?var10.       FILTER(?var10 >= 5000 && ?var10 <= 10000 ) }\n----\nHTTP error (most likely invalid query)\n49\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {   <y2geoo:osm_city_Thessaloniki> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    ?var4 rdf:type <y2geoo:OSM_lake> .     ?var4 geo:hasGeometry ?var6 .  ?var6 geo:asWKT ?var8 .      FILTER(strdf:below(?var8,?var3))    FILTER (strdf:northOf(?var8,<yago:Athens>(<yago:location>) )) } ORDER BY DESC(strdf:area(?var8)) LIMIT 1\n----\n2\n50\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {  <yago:Key_Largo> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .   ?var0 rdf:type y2geoo:GADM_2ndOrder_AdministrativeUnit . ?var0 geo:hasGeometry ?var6 .  ?var6 geo:asWKT ?var8 .    FILTER(strdf:sfWithin(?var3 , ?var8)) }\n----\n2\n51\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   <yago:Greece> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    ?var0 rdf:type y2geoo:OSM_bay;         geo:hasGeometry ?var5 .  ?var5 geo:asWKT ?var7 .     ?var8 rdf:type y2geoo:OSM_reservoir;         geo:hasGeometry ?var9 .  ?var9 geo:asWKT ?var11 .      FILTER(strdf:left(?var7, ?var11) && strdf:within(?var11, ?var3)) }\n----\n2\n52\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {   ?var1 rdf:type y2geoo:GAG_Region .   ?var1 y2geoo:hasGADM_Version \"1\" .   ?var1 y2geoo:hasPopulation ?var0 }  ORDER BY DESC(xsd:double(?var0)) LIMIT 1\n----\n2\n53\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:Dublin> geo:hasGeometry ?var0 .  ?var0 geo:asWKT ?var2 .   <yago:Norilsk> geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    FILTER(strdf:above(?var5, ?var2)) }\n----\n2\n54\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  ?var0 geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .   <yago:Helston> geo:hasGeometry ?var4 .  ?var4 geo:asWKT ?var6 .    FILTER(strdf:right(?var3 , ?var6 )) }\n----\n3\n55\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   <y2geoo:OSM_village> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    <y2geoo:NBD_State> geo:hasGeometry ?var4 .  ?var4 geo:asWKT ?var6 .     ?var0 rdf:type y2geoo:OSM_forest;         geo:hasGeometry ?var9 .  ?var9 geo:asWKT ?var11 .      FILTER(strdf:intersects(?var11, strdf:buffer(?var3, 0, uom:metre))) }\n----\n3\n56\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <y2geoo:GAG_Municipality> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var3 .  <yago:Gravia> geo:hasGeometry ?var4 . ?var4 geo:asWKT ?var6 . FILTER(geof:sfWithin(strdf:buffer(?var6, 0 , uom:metre), strdf:buffer(?var3, 0 , uom:metre))) SELECT (SUM(?var0) AS ?var0) WHERE {  <yago:Gravia>     <p:population> ?var0. } }\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T15:57:05.169+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n57\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_interContinental; geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_state;     geo:hasGeometry ?var7 .  ?var7 geo:asWKT ?var9 .      FILTER(strdf:within(?var5 , ?var9)) }\n----\n3\n58\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_bay;     geo:hasGeometry ?var3.   ?var3 geo:asWKT ?var5.    ?var6 rdf:type y2geoo:OSM_village;     geo:hasGeometry ?var7.   ?var7 geo:asWKT ?var9.      FILTER(strdf:intersects(?var5, ?var9)) }\n----\n3\n59\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {  <yago:Liverpool> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var3 . ?var0 rdf:type y2geoo:OSM_park; geo:hasGeometry ?var5 . ?var5 geo:asWKT ?var7 . FILTER(geof:sfWithin(?var7, ?var3)) }\n----\n3\n60\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSI_Barony;     geo:hasGeometry ?var2 .  ?var0 rdf:type y2geoo:OSM_lake;     geo:hasGeometry ?var4 .  FILTER(geof:sfWithin(?var4 , ?var2 )) }\n----\n4\n61\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:Southampton_F.C._1780> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n4\n62\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   <yago:New_York_City> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    ?var0 rdf:type y2geoo:OSM_church ;     geo:hasGeometry ?var5 .  ?var5 geo:asWKT ?var7 .      FILTER(strdf:within(?var7, ?var3)) }\n----\n4\n63\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (strdf:length( ?var0 ) AS ?var1) WHERE {  <yago:Loch_Ave> geo:hasGeometry ?var2 . ?var2 geo:asWKT ?var4 . ?var0  y2geoo:transformsToMeter(?var4). }\n----\n4\n64\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:geoentity_City_of_Plymouth_8133742> geo:hasGeometry ?var0 . ?var0 geo:asWKT ?var2 . <yago:geoentity_City_and_County_of_Cardiff_6705974> geo:hasGeometry ?var3 . ?var3 geo:asWKT ?var5 . FILTER(geof:distance(?var2 , ?var5 , uom:metre)<10000 ) }\n----\n5\n65\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:geoentity_City_of_Belfast_3124065> geo:hasGeometry ?var0 . ?var0 geo:asWKT ?var2 .  <yago:geoentity_City_of_London_8104079> geo:hasGeometry ?var3 . ?var3 geo:asWKT ?var5 . FILTER(strdf:left(?var2 , ?var5 )) }\n----\n6\n66\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:Scotland> geo:hasGeometry ?var0 . ?var0 geo:asWKT ?var2 . <yago:geoentity_Sfakia_8136749> geo:hasGeometry ?var3 . ?var3 geo:asWKT ?var5 . FILTER(geof:sfWithin(?var5, ?var2)) }\n----\n7\n67\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:United_States> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .   <yago:New_York_City>     rdf:type         <y2geoo:GADM_2ndOrderEntity>.    <y2geoo:OSM_city>     rdf:type         <y2geoo:GADM_2ndOrderEntity>.    <y2geoo:OSM_city>     geo:hasGeometry ?var7 .  ?var7 geo:asWKT ?var9 .      FILTER(strdf:intersects(?var3 , ?var9 )) } SELECT (strdf:lat(?var3) as ?var0) (strdf:lon(?var3) as ?var12)\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:00:58.830+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n68\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type <y2geoo:OS_County>;     geo:hasGeometry ?var2.   ?var2 geo:asWKT ?var4.    BIND(xsd:float(strdf:area(?var4)) as ?var0) } ORDER BY ASC (?var0) LIMIT 2\n----\n7\n69\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type  y2geoo:OS_County .   ?var1 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    yago:Kansas geo:hasGeometry ?var6 .   ?var6 geo:asWKT ?var8 .     FILTER(strdf:within(?var5 , ?var8))      ?var0  <pct:population>  ?var10 } ORDER BY (xsd:float(?var10)) LIMIT 1\n----\n7\n70\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var0 rdf:type y2geoo:GAG_Municipality .   ?var0 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    FILTER(strdf:within(strdf:buffer(?var5 , 0, uom:metre), strdf:buffer(?var6 , 0, uom:metre)))     ?var0 <pont:population> ?var8.      FILTER (?var8<30000) }\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:01:54.349+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\n7\n71\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {   ?var1 rdf:type y2geoo:GADM_3rdOrder_AdministrativeUnit . ?var1 geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_city . ?var6 geo:hasGeometry ?var8 . ?var8 geo:asWKT ?var10 . FILTER(strdf:within(?var10 , ?var5)) } ORDER BY DESC (xsd:double(?var0)) LIMIT 1\n----\n7\n72\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (xsd:integer(?var0) as ?var1) WHERE {  <yago:Dublin>     y2geoo:hasGADM_Population ?var0 . }\n----\n7\n73\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {   <yago:Kent> geo:hasGeometry ?var0 .   ?var0 geo:asWKT ?var2 .    <yago:Oxfordshire> geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .     FILTER(geof:distance(?var2 , ?var5 , uom:metre) > 1e4 ) }\n----\n8\n74\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  y2geoo:OSM_city geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var3 .  y2geoo:OSM_population_density geo:hasGeometry ?var4 . ?var4 geo:asWKT ?var6 . FILTER(strdf:within(?var6 , ?var3)) } ORDER BY DESC (?var0) LIMIT 1\n----\n8\n75\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE { yago:United_Kingdom geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var3 . ?var4 rdf:type y2geoo:OSM_lake ; geo:hasGeometry ?var5 . ?var5 geo:asWKT ?var7 . BIND(strdf:buffer(?var3, ?var7, 0)) as ?var0 }\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:04:02.502+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n76\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var0 rdf:type y2geoo:GAG_Municipity .   ?var0 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    <yago:Greece>     geo:hasGeometry ?var6 .      ?var6 geo:asWKT ?var8 .        FILTER(strdf:within(?var5 , ?var8)) } ORDER BY ASC (xsd:double(?var9)) LIMIT 3\n----\n8\n77\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:Drogheda> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n8\n78\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSM_island .   ?var1 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    FILTER(strdf:isWithin(?var5 , <http://www.geo-coordinates.com/Greece_(49687)_with_Geography_Coordinate_System_-_EPSG_4326._gcr>))  ?var1 yago:hasNestingUnit ?var0 .     ?var0 geo:hasGeometry ?var10 .   ?var10 geo:asWKT ?var12 .      FILTER (strdf:isWithin(?var12,?var5)).    ?var13 rdf:type y2geoo:OSM_beach;         geo:hasGeometry ?var14.     ?var14 geo:asWKT ?var16.       FILTER(geof:sfContains(?var12,?var16) ) } ORDER BY DESC(COUNT(?var0 )) LIMIT 1\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:05:00.891+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\n8\n79\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   ?var0 rdf:type y2geoo:OSM_stream;   geo:hasGeometry ?var3.   ?var3 geo:asWKT ?var5.   <yago:Alabama> geo:hasGeometry ?var6.   ?var6 geo:asWKT ?var8.  FILTER(geof:sfWithin(?var5, ?var8)) }\n----\n8\n80\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (strdf:distance(?var0 , ?var1) as ?var2) WHERE {  <yago:Dublin> geo:hasGeometry ?var3 . ?var3 geo:asWKT ?var5 . <yago:Howth> geo:hasGeometry ?var6 . ?var6 geo:asWKT ?var1 . FILTER(geof:sfContains(?var5, ?var1)) }\n----\n8\n81\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSI_County_Council_Area .   ?var1 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_nature_reserve .   ?var6 geo:hasGeometry ?var8 .   ?var8 geo:asWKT ?var10 .     FILTER(strdf:within(?var10,?var5))  ?var14 rdf:type y2geoo:OSM_lake .   ?var14 geo:hasGeometry ?var16 .   ?var16 geo:asWKT ?var18 .      FILTER(strdf:within(?var18,?var10)). }\n----\n8\n82\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:Leicester> geo:hasGeometry ?var0 .  ?var0 geo:asWKT ?var2 .   <yago:Birmingham> geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    FILTER(strdf:right(?var2 , ?var5 )) }\n----\n9\n83\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSIA_County_AdministrationArea .   ?var1 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    ?var6 rdf:type y2geoo:OSM_park .   ?var6 geo:hasGeometry ?var8 .   ?var8 geo:asWKT ?var10 .     FILTER(strdf:within(?var10 , ?var5))  ?var11 rdf:type y2geoo:OSM_forest .   ?var11 geo:hasGeometry ?var13 .   ?var13 geo:asWKT ?var15 .      FILTER(strdf:within(?var15 , ?var5 )) }\n----\n9\n84\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   <y2geoo:OS_District> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    <yago:Cambridge> geo:hasGeometry ?var4 .  ?var4 geo:asWKT ?var6 .     ?var0 rdf:type y2geoo:OSM_forest;         geo:hasGeometry ?var9 .  ?var9 geo:asWKT ?var11 .      FILTER(strdf:within(?var11, strdf:buffer(?var6, 0, uom:metre), uom:metre))  FILTER(strdf:within(?var3, strdf:buffer(?var11, 0, uom:metre), uom:metre)) }\n----\n9\n85\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:geoentity_Luton_3142675> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n9\n86\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OS_District;     geo:hasGeometry ?var2 .  ?var2 geo:asWKT ?var4 .    ?var0 rdf:type y2geoo:OSM_village;     geo:hasGeometry ?var6 .  ?var6 geo:asWKT ?var8 .    FILTER(strdf:within(?var8,?var4)) } ORDER BY DESC (COUNT(DISTINCT ?var0) ) LIMIT 1\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:08:08.838+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n87\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (SUM(?var0) AS ?var1) WHERE {   ?var2 rdf:type y2geoo:GADM_3rdOrder_AdministrativeUnit .   ?var2 geo:hasGeometry ?var4 .   ?var4 geo:asWKT ?var6 .    FILTER(strdf:within(?var7 , strdf:buffer(?var8, 0, uom:metre), strdf:transform(?var9 , <http://www.opengis.net/def/crs/EPSG/0/4326>)))     ?var2 y2geoo:POPULATION ?var0 } ORDER BY DESC(?var0) LIMIT 5\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:08:37.874+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\n9\n88\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSM_city;     geo:hasGeometry ?var2 .  ?var2 geo:asWKT ?var4 .    ?var5 rdf:type y2geoo:OSM_lake;     geo:hasGeometry ?var6 .  ?var6 geo:asWKT ?var8 .      FILTER(strdf:within(?var8 , strdf:buffer(?var4 , 0, uom:metre))) } GROUP BY (?var0) ORDER BY DESC(COUNT(DISTINCT ?var1)) LIMIT 1\n----\n9\n89\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:Chichester> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n9\n90\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nASK {  <yago:Belfast> geo:hasGeometry ?var0 .  ?var0 geo:asWKT ?var2 .   <yago:Dublin> geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    FILTER(strdf:below(?var2, ?var5)) }\n----\n9\n91\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSM_park;     geo:hasGeometry ?var2.   ?var2 geo:asWKT ?var4.    <yago:Dublin>  geo:hasGeometry ?var6.      ?var6 geo:asWKT ?var8.        FILTER(strdf:area(?var4) > strdf:area(?var8)). } ORDER BY DESC (strdf:area(?var4)) LIMIT 1\n----\n9\n92\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   <yago:Stafford> geo:hasGeometry ?var1 .  ?var1 geo:asWKT ?var3 .    ?var0 rdf:type y2geoo:OSI_District;     geo:hasGeometry ?var5 .  ?var5 geo:asWKT ?var7 .      FILTER(strdf:touches(?var3 , strdf:buffer(?var7 , 0, uom:metre))) }\n----\n9\n93\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:GADM_3rdOrder_AdministrativeUnit .   ?var1 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    <yago:Central_Macedonia>  rdf:type     y2geoo:GADM_2ndOrder_AdministrativeUnit .      <yago:Central_Macedonia>  geo:hasGeometry ?var8 .       ?var8 geo:asWKT ?var10 .        FILTER(strdf:within(?var5 , ?var10))     ?var0 rdf:type y2geoo:OSM_lake;         geo:hasGeometry ?var12.          ?var12 geo:asWKT ?var14.           FILTER (strdf:within(?var14,?var5)). }\n----\n9\n94\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT (MIN(strdf:area(?var0)) as ?var1) WHERE {   ?var2 rdf:type y2geoo:GAG_Municipality .  ?var2 geo:hasGeometry ?var4.  ?var4 geo:asWKT ?var0. } ORDER BY ASC(?var1) LIMIT 1\n----\n9\n95\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {   ?var1 rdf:type y2geoo:GAG_Municipality .  ?var1 geo:hasGeometry ?var3 .  ?var3 geo:asWKT ?var5 .    <yago:Thessaloniki>     geo:hasGeometry ?var6 .  ?var6 geo:asWKT ?var8 .      FILTER(strdf:touches(?var5 , ?var8 )) } ORDER BY DESC (xsd:decimal(strdf:area(?var5))) LIMIT 1\n----\n9\n96\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var0 rdf:type y2geoo:GAG_Municipality .   ?var0 geo:hasGeometry ?var3 .   ?var3 geo:asWKT ?var5 .    FILTER(strdf:within(strdf:buffer(?var6 , 0 , uom:metre), strdf:buffer(?var5 , 0 , uom:metre)))     ?var8 rdf:type y2geoo:OSM_lake .      ?var8 geo:hasGeometry ?var10 .       ?var10 geo:asWKT ?var12 .        FILTER(geof:sfWithin(?var12, ?var5)) }\n----\nMaterialize failed: {\"timestamp\":\"2024-09-22T16:11:43.768+00:00\",\"status\":500,\"error\":\"Internal Server Error\",\"path\":\"/materialize-api\"}\nHTTP error (most likely invalid query)\n97\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT DISTINCT ?var0 WHERE {   ?var1 rdf:type y2geoo:OSI_Barony;     geo:hasGeometry ?var2 .  ?var0 rdf:type y2geoo:OSM_forest;     geo:hasGeometry ?var4 .  ?var2 geo:asWKT ?var6 .  ?var4 geo:asWKT ?var8 .  FILTER(strdf:within(?var8 , ?var6 )) }\n----\n9\n98\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT ?var0 WHERE {  <yago:Birmingham> geo:hasGeometry ?var1 . ?var1 geo:asWKT ?var0 }\n----\n9\n99\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----\nSELECT (COUNT(DISTINCT ?var0) AS ?var1) WHERE {   yago:Merseyside geo:hasGeometry ?var2 .  ?var2 geo:asWKT ?var4 .    ?var0 rdf:type y2geoo:OSM_city;     geo:hasGeometry ?var6 .  ?var6 geo:asWKT ?var8 .    FILTER(strdf:within(?var8,?var4)) }\n----\n10\n0.1\n","output_type":"stream"}]}]}